CATEGORY 3.1,,,,,,,,,,,,,,,,,,,,,
Scopus search query:,,,"TITLE-ABS-KEY ( ( ( ""PointNet"" OR ""PointNet++"" OR ""PointCNN"" OR ""DGCNN"" OR ""KPConv"" OR ""PointConv"" OR ""Point transformer"" OR ""ShellNet"" OR ""PointBERT"" OR ""CurverNet"" OR ""Self organizing network"" ) AND ( ""3D data"" OR ""pointcloud"" OR ""point cloud"" ) AND ( ""construction industry"" OR ""building"" OR ""AEC"" OR ""BIM"" ) ) ) AND PUBYEAR > 2007 AND PUBYEAR < 2025 AND ( LIMIT-TO ( DOCTYPE,""ar"" ) OR LIMIT-TO ( DOCTYPE,""cp"" ) )  AND ( LIMIT-TO ( LANGUAGE,""English"" ) ) ",,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,
Authors,Author full names,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Abstract,Author Keywords,Document Type,Publication Stage,Open Access,Source,EID
Morbidoni C.; Pierdicca R.; Quattrini R.; Frontoni E.,"Morbidoni, C. (15136812700); Pierdicca, R. (56460209100); Quattrini, R. (55755385800); Frontoni, E. (9737451300)",15136812700; 56460209100; 55755385800; 9737451300,GRAPH CNN with RADIUS DISTANCE for SEMANTIC SEGMENTATION of HISTORICAL BUILDINGS TLS POINT CLOUDS,2020,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",44,4/W1,,95,102,7,5,10.5194/isprs-archives-XLIV-4-W1-2020-95-2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092168510&doi=10.5194%2fisprs-archives-XLIV-4-W1-2020-95-2020&partnerID=40&md5=bb9a4fc15828487f54dee17625dbae64,"Point clouds obtained via Terrestrial Laser Scanning (TLS) surveys of historical buildings are generally transformed into semantically structured 3D models with manual and time-consuming workflows. The importance of automatizing this process is widely recognized within the research community. Recently, deep neural architectures have been applied for semantic segmentation of point clouds, but few studies have evaluated them in the Cultural Heritage domain, where complex shapes and mouldings make this task challenging. In this paper, we describe our experiments with the DGCNN architecture to semantically segment historical buildings point clouds, acquired with TLS. We propose a variation of the original approach where a radius distance based technique is used instead of K-Nearest Neighbors (KNN) to represent the neighborhood of points. We show that our approach provides better results by evaluating it on two real TLS point clouds, representing two Italian historical buildings: the Ducal Palace in Urbino and the Palazzo Ferretti in Ancona.  © Authors 2020.",,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85092168510
Li L.; Song N.; Sun F.; Liu X.; Wang R.; Yao J.; Cao S.,"Li, Li (57037167200); Song, Nan (57471484600); Sun, Fei (56997988000); Liu, Xinyi (56734755200); Wang, Ruisheng (55717757900); Yao, Jian (55311401100); Cao, Shaosheng (57201750929)",57037167200; 57471484600; 56997988000; 56734755200; 55717757900; 55311401100; 57201750929,Point2Roof: End-to-end 3D building roof modeling from airborne LiDAR point clouds,2022,ISPRS Journal of Photogrammetry and Remote Sensing,193,,,17,28,11,7,10.1016/j.isprsjprs.2022.08.027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137619452&doi=10.1016%2fj.isprsjprs.2022.08.027&partnerID=40&md5=f7028dfc3039b8129a84f0d9afbed576,"Three-dimensional (3D) building roof reconstruction from airborne LiDAR point clouds is an important task in photogrammetry and computer vision. To automatically reconstruct the 3D building models at Level of Detail 2 (LoD-2) from airborne LiDAR point clouds, the data-driven approaches usually need to be performed in two steps: geometric primitive extraction and roof structure inference. Obviously, the traditional approaches are not end-to-end, the accumulated errors in different stages cannot be avoided and the final 3D roof models may not be optimal. In addition, the results of 3D roof models largely depend on the accuracy of geometric primitives (planes, lines, etc.). To solve these problems, we present a deep learning-based approach to directly reconstruct building roofs from airborne LiDAR point clouds, named Point2Roof. In our method, we start by extracting the deep features for each input point using PointNet++. Then, we identify a set of candidate corner points from the input point clouds using the extracted deep features. In addition, we also regress the offset for each candidate corner point to refine their locations. After that, these candidates are clustered into a set of initial vertices, and we further refine their locations to obtain the final accurate vertices. Finally, we propose a Paired Point Attention (PPA) module to predict the true model edges from an exhaustive set of candidate edges between the vertices. Unlike traditional roof modeling approaches, the proposed Point2Roof is end-to-end. However, due to the lack of a building reconstruction dataset, we construct a large-scale synthetic dataset to verify the effectiveness and robustness of the proposed Point2Roof. The experimental results conducted on the synthetic benchmark demonstrate that the proposed Point2Roof significantly outperforms the traditional roof modeling approaches. The experiments also show that the network trained on the synthetic dataset can be applied to the real point clouds after fine-tuning the trained model on a small real dataset. The large-scale synthetic dataset, the small real dataset and the source code of our approach are publicly available in https://github.com/Li-Li-Whu/Point2Roof. © 2022 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Airborne LiDAR; Building reconstruction; Deep learning; Point clouds; Roof modeling,Article,Final,,Scopus,2-s2.0-85137619452
Zhang C.; Fan H.,"Zhang, Chaoquan (46061737700); Fan, Hongchao (55368902500)",46061737700; 55368902500,An Improved Multi-Task Pointwise Network for Segmentation of Building Roofs in Airborne Laser Scanning Point Clouds,2022,Photogrammetric Record,37,179,,260,284,24,4,10.1111/phor.12420,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133962531&doi=10.1111%2fphor.12420&partnerID=40&md5=5cd01f62c8224c949e16dacdf595fbbc,"Roof plane segmentation is an essential step in the process of 3D building reconstruction from airborne laser scanning (ALS) point clouds. The existing approaches either rely on human intervention to select the appropriate input parameters for different data-sets or they are not automatic and efficient. To tackle these issues, an improved multi-task pointwise network is proposed to simultaneously segment instances (that is, individual roof planes) and semantics (that is, groups of roof planes with similar geometric shapes) in point clouds. PointNet++ is used as a backbone network to extract robust features in the first step. The features from semantics branch are then added to the instance branch to facilitate the learning of instance embeddings. After that, a feature fusion module is added to the semantics branch to acquire more discriminative features from the backbone network. To increase the accuracy of semantic predictions, fused semantic features of the points belonging to the same instance are aggregated together. Finally, a mean-shift clustering algorithm is employed on instance embeddings to produce the instance predictions. Furthermore, a new roof data-set (called RoofNTNU) is established by taking ALS point clouds as training data for automatic and more general segmentation. Experiments on the new roof data-set show that the method achieves promising segmentation results: the mean precision (mPrec) of 96.2% for the instance segmentation task and mean accuracy (mAcc) of 94.4% for the semantic segmentation task. © 2022 The Authors. The Photogrammetric Record published by Remote Sensing and Photogrammetry Society and John Wiley & Sons Ltd.",airborne laser scanning (ALS) point clouds; data-set; instance segmentation; roof plane segmentation,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85133962531
Uggla G.; Horemuz M.,"Uggla, Gustaf (57203990214); Horemuz, Milan (6508381346)",57203990214; 6508381346,Identifying roadside objects in mobile laser scanning data using image-based point cloud segmentation,2020,Journal of Information Technology in Construction,25,,,545,560,15,4,10.36680/J.ITCON.2020.031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099292194&doi=10.36680%2fJ.ITCON.2020.031&partnerID=40&md5=41a6b3d7c474156cb853926f99f02c75,"Capturing geographic information from a mobile platform, a method known as mobile mapping, is today one of the best methods for rapid and safe data acquisition along roads and railroads. The digitalization of society and the use of information technology in the construction industry is increasing the need for structured geometric and semantic information about the built environment. This puts an emphasis on automatic object identification in data such as point clouds. Most point clouds are accompanied by RGB images, and a recent literature review showed that these are possibly underutilized for object identification. This article presents a method (image-based point cloud segmentations - IBPCS) where semantic segmentation of images is used to filter point clouds, which drastically reduces the number of points that have to be considered in object identification and allows simpler algorithms to be used. An example implementation where IBPCS is used to identify roadside game fences along a country road is provided, and the accuracy and efficiency of the method is compared to the performance of PointNet, which is a neural network designed for end-to-end point cloud classification and segmentation. The results show that our implementation of IBPCS outperforms PointNet for the given task. The strengths of IBPCS are the ability to filter point clouds based on visual appearance and that it efficiently can process large data sets. This makes the method a suitable candidate for object identification along rural roads and railroads, where the objects of interest are scattered over long distances. COPYRIGHT: © 2020 The author(s). This is an open access article distributed under the terms of the Creative Commons Attribution 4.0 International (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.",Deep learning; Laser scanning; Mobile mapping; Object identification; Point clouds,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85099292194
Guiotte F.; Rao M.B.; Lefèvre S.; Tang P.; Corpetti T.,"Guiotte, F. (57209605840); Rao, M.B. (57210958606); Lefèvre, S. (57203070803); Tang, P. (35436105100); Corpetti, T. (14018992700)",57209605840; 57210958606; 57203070803; 35436105100; 14018992700,Relation network for full-waveforms LiDAR classification,2020,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",43,B3,,515,520,5,1,10.5194/isprs-archives-XLIII-B3-2020-515-2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091158617&doi=10.5194%2fisprs-archives-XLIII-B3-2020-515-2020&partnerID=40&md5=176ade9c6ccb04e7c513d190811d0514,"LiDAR data are widely used in various domains related to geosciences (flow, erosion, rock deformations, etc.), computer graphics (3D reconstruction) or earth observation (detection of trees, roads, buildings, etc.). Because of the unstructured nature of remaining 3D points and because of the cost of acquisition, the LiDAR data processing is still challenging (few learning data, difficult spatial neighboring relationships, etc.). In practice, one can directly analyze the 3D points using feature extraction and then classify the points via machine learning techniques (Brodu, Lague, 2012, Niemeyer et al., 2014, Mallet et al., 2011). In addition, recent neural network developments have allowed precise point cloud segmentation, especially using the seminal pointnet network and its extensions (Qi et al., 2017a, Riegler et al., 2017). Other authors rather prefer to rasterize / voxelize the point cloud and use more conventional computers vision strategies to analyze structures (Lodha et al., 2006). In a recent work, we demonstrated that Digital Elevation Models (DEM) is reductive of the vertical component complexity describing objects in urban environments (Guiotte et al., 2020). These results highlighted the necessity to preserve the 3D structure of the point cloud as long as possible in the processing. In this paper, we therefore rely on ortho-waveforms to compute a land cover map. Ortho-waveforms are directly computed from the waveforms in a regular 3D grid. This method provides volumes somehow ""similar"" to hyperspectral data where each pixel is here associated with one ortho-waveform. Then, we exploit efficient neural networks adapted to the classification of hyperspectral data when few samples are available. Our results, obtained on the 2018 Data Fusion Contest dataset (DFC), demonstrate the efficiency of the approach. © 2020 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives.",full waveform; land cover mapping; LiDAR data; relation network,Conference paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85091158617
Soilán M.; Lindenbergh R.; Riveiro B.; Sánchez-Rodríguez A.,"Soilán, M. (56803886700); Lindenbergh, R. (7801611878); Riveiro, B. (35096575300); Sánchez-Rodríguez, A. (57200043734)",56803886700; 7801611878; 35096575300; 57200043734,POINTNET for the AUTOMATIC CLASSIFICATION of AERIAL POINT CLOUDS,2019,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",4,2/W5,,445,452,7,16,10.5194/isprs-annals-IV-2-W5-445-2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067436995&doi=10.5194%2fisprs-annals-IV-2-W5-445-2019&partnerID=40&md5=b6d35c5bc45a912a7b6364ba4c572c7b,"During the last couple of years, there has been an increased interest to develop new deep learning networks specifically for processing 3D point cloud data. In that context, this work intends to expand the applicability of one of these networks, PointNet, from the semantic segmentation of indoor scenes, to outdoor point clouds acquired with Airborne Laser Scanning (ALS) systems. Our goal is to of assist the classification of future iterations of a national wide dataset such as the Actueel Hoogtebestand Nederland (AHN), using a classification model trained with a previous iteration. First, a simple application such as ground classification is proposed in order to prove the capabilities of the proposed deep learning architecture to perform an efficient point-wise classification with aerial point clouds. Then, two different models based on PointNet are defined to classify the most relevant elements in the case study data: Ground, vegetation and buildings. While the model for ground classification performs with a F-score metric above 96%, motivating the second part of the work, the overall accuracy of the remaining models is around 87%, showing consistency across different versions of AHN but with improvable false positive and false negative rates. Therefore, this work concludes that the proposed classification of future AHN iterations is feasible but needs more experimentation. © Authors 2019.",Aerial Laser Scanner; Deep Learning; Point Cloud Classification; Semantic Segmentation,Conference paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85067436995
Sahebdivani S.; Arefi H.; Maboudi M.,"Sahebdivani, Shima (57217682813); Arefi, Hossein (14031194500); Maboudi, Mehdi (23994453500)",57217682813; 14031194500; 23994453500,Deep Learning based Classification of Color Point Cloud for 3D Reconstruction of Interior Elements of Buildings,2020,"Iranian Conference on Machine Vision and Image Processing, MVIP",2020-February,,9116894,,,,3,10.1109/MVIP49855.2020.9116894,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087521271&doi=10.1109%2fMVIP49855.2020.9116894&partnerID=40&md5=2265d429042a973edc6c791339c784c8,"In architecture and engineering, the production of 3D models of various objects that are both simple and most closely related to reality is of particular importance. In this article, we are going to model different aspects of the interior of a building, which is performed in three general steps. In the first step, the existing point clouds of a room are semantically segmented using the PointNet Deep Learning Network. Each class of objects is then reconstructed using three methods including: Poisson, ball-pivoting and combined volumetric triangulation method and marching cubes. In the last step, each model is simplified by the methods of vertex clustering and edge collapse with quadratic error. Results are quantitatively and qualitatively evaluated for two types of objects, one with simple geometry and one with complex geometry. After selecting the optimal surface reconstruction method and simplifying it, all the objects are modeled. According to the results, the Poisson surface reconstruction method with a simplified edge collapse method provides better geometric accuracy of 0.1 mm for simpler geometry classes. In addition, for more complex geometry problems, the model produced by combined volumetric triangulation method and marching cubes with simplified edge collapse method was more suitable due to a higher accuracy of 0.022 mm. © 2020 IEEE.",3d reconstruction; deep learning; interior point cloud; model simplification; semantic segmentation,Conference paper,Final,,Scopus,2-s2.0-85087521271
An J.; Zhang J.; Ma M.,"An, Jiang (58296171500); Zhang, Jiuhong (23089281200); Ma, Mingxiao (57217490474)",58296171500; 23089281200; 57217490474,Research on the Intelligent Auxiliary Design of Subway Station Building Space Based on Deep Learning,2023,Applied Sciences (Switzerland),13,16,9242,,,,0,10.3390/app13169242,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169092912&doi=10.3390%2fapp13169242&partnerID=40&md5=a0014e2bf3e1ad2b77f1b9550cba493f,"In recent years, deep learning methods have been used with increasing frequency to solve architectural design problems. This paper aims to study the spatial functional layout of deep learning-assisted generation subway stations. Using the PointNet++ model, the subway station point cloud data are trained and then collected and processed by the author. After training and verification, the following conclusions are obtained: (1) the feasibility of spatial deep learning for construction based on PointNet++ in the form of point cloud data is verified; (2) the effectiveness of PointNet++ for the semantic segmentation and prediction of metro station point cloud information is verified; and (3) the results show that the overall 9:1 training prediction data have 60% + MIOU and 75% + accuracy for 9:1 training prediction data in the space of 20 × 20 × 20 and a block_size of 10.0. This paper combines the deep learning of 3D point cloud data with architectural design, breaking through the original status quo of two-dimensional images as research objects. From the dataset level, the limitation that research objects such as 2D images cannot accurately describe 3D space is avoided, and more intuitive and diverse design aids are provided for architects. © 2023 by the authors.",architectural design; convolutional neural networks; deep learning; PointNet++; subway station space,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85169092912
Ma J.W.; Leite F.,"Ma, Jong Won (57192367343); Leite, Fernanda (23097703400)",57192367343; 23097703400,Performance boosting of conventional deep learning-based semantic segmentation leveraging unsupervised clustering,2022,Automation in Construction,136,,104167,,,,7,10.1016/j.autcon.2022.104167,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124537832&doi=10.1016%2fj.autcon.2022.104167&partnerID=40&md5=1add189518d2cbaac841dbed862fcf48,"In Scan-to-BIM, semantically understanding 3D point clouds is an essential process that must precede 3D BIM elements generation. The main idea of this research stemmed from an assumption where recognizing a group of points would be simpler than assigning label per point from the machine's perspective when using deep learning classifiers. To validate our assumption, conventional point-wise classification problem was formulated as segment-wise classification problem leveraging unsupervised clustering. A single parameter executable hierarchical density-based algorithm and PointNet-based algorithms are chosen for segmentation and classification purposes. Using same baseline architecture, our segment-wise classification framework showed performance boosts of 1.12% and 7.66% for S3DIS and 3DFacilities compared to point-wise classification approach. Solving the nature of class imbalance problem and dataset augmentation ability are determined to be the contributing factors for showing superior results. Given semantic segmentation deep learning algorithm, our proposed framework provides an opportunity to improve the performance leveraging unsupervised method. © 2022 Elsevier B.V.",Deep learning; Hierarchical density-based spatial clustering of applications with noise; Point clouds; Scan-to-BIM; Semantic segmentation,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85124537832
Cao Y.; Teruggi S.; Fassi F.; Scaioni M.,"Cao, Yuwei (57219026348); Teruggi, Simone (57190034210); Fassi, Francesco (54787529900); Scaioni, Marco (8261815100)",57219026348; 57190034210; 54787529900; 8261815100,A Comprehensive Understanding of Machine Learning and Deep Learning Methods for 3D Architectural Cultural Heritage Point Cloud Semantic Segmentation,2022,Communications in Computer and Information Science,1651 CCIS,,,329,341,12,2,10.1007/978-3-031-17439-1_24,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141740596&doi=10.1007%2f978-3-031-17439-1_24&partnerID=40&md5=d083fb96efc5c7e8b426515493e1bbbc,"As a result of the development of Artificial Intelligence (AI) techniques, in recent years, machine learning (ML) and deep learning (DL) approaches have been widely used to semantically enrich 3D architectural cultural heritage (ACH) point clouds. While existing approaches for analyzing and interpreting point clouds continue to improve, the generalizability of pre-trained ML and DL methods to various types of historic buildings remains uncertain. In this context, a comprehensive understanding of both methodologies can enable us to make more effective use of AI techniques in the ACH domain (e.g., data exploitation, model definition, analysis, and preservation). This work presents and compares two very different approaches for the 3D ACH semantic segmentation task. Specifically, we train and test a ML method based on the Random Forest (RF) classifier on the point cloud of three chapels part of the “Sacromonte Calvario di Domodossola” and on the two test scenes of the ArCH dataset. Then, we employ dynamic graph convolutional neural network (DGCNN) as our DL method, training on the ArCH dataset and testing on both the two unseen test scenes of the ArCH dataset and on the “Sacrimonti” chapel point clouds. We provide empirical experiments to illustrate the efficiency of applying ML and DL methodologies to ACH point clouds. Following that, the advantages and limitations of these two approaches are evaluated through a systematic study of the classification results. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",3D point cloud; Architectural heritage; Classification; Deep learning; Machine learning,Conference paper,Final,,Scopus,2-s2.0-85141740596
Hamid N.; Wibisono A.; Anwar Ma'Sum M.; Gamal A.; Ardhianto R.; Arymurthy A.M.; Jatmiko W.,"Hamid, Nur (52663351300); Wibisono, Ari (55625531300); Anwar Ma'Sum, M. (57213817389); Gamal, Ahmad (57200131887); Ardhianto, Roni (57200085262); Arymurthy, Aniati Murni (36815724000); Jatmiko, Wisnu (8568432600)",52663351300; 55625531300; 57213817389; 57200131887; 57200085262; 36815724000; 8568432600,3D Edge Convolution in Deep Neural Network Implementation for Land Cover Semantic Segmentation of Airborne LiDAR Data,2019,"2019 4th Asia-Pacific Conference on Intelligent Robot Systems, ACIRS 2019",,,8935980,216,220,4,1,10.1109/ACIRS.2019.8935980,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078064012&doi=10.1109%2fACIRS.2019.8935980&partnerID=40&md5=5fc7b5538adcf1089d57d7388b5d09df,"3-dimensional data contains more informative visualization than a 2-dimensional one. LiDAR sensor produces 3D data or point cloud data. There have been many implementations of LiDAR data such as for building detection, urban area modeling, and land cover analysis. This study will analyze land cover because of its substantial benefits. The purpose of this study is to produce semantic segmentation of land cover from LiDAR data by implementing EdgeConv Algorithm from Dynamic Graph Convolutional Neural Network (DGCNN). The dataset in this study is LiDAR data of Kupang, one of the areas in Indonesia. This work achieves the average accuracy of 67.76% for DGCNN better than the state-of-the-art method PointNet (previous method) with 64.97% by implementing the point cloud dataset from LiDAR data of Kupang. This is because the edge convolution could recognize the global shape structure and local neighborhood information so that it could improve the segmentation performance result. © 2019 IEEE.",3-dimensional edge detection; 3D CNN; edge convolution; land cover; lidar; semantic segmentation,Conference paper,Final,,Scopus,2-s2.0-85078064012
De Gélis I.; Lefèvre S.; Corpetti T.,"De Gélis, I. (57218881194); Lefèvre, S. (57203070803); Corpetti, T. (14018992700)",57218881194; 57203070803; 14018992700,3D urban change detection with point cloud siamese networks,2021,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",43,B3-2021,,879,886,7,6,10.5194/isprs-archives-XLIII-B3-2021-879-2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115854172&doi=10.5194%2fisprs-archives-XLIII-B3-2021-879-2021&partnerID=40&md5=ac1d86166b61c3c6fd58061c787dc443,"As the majority of the earth population is living in urban environments, cities are continuously evolving and efficient monitoring tools are needed to retrieve and classify their evolution. In this context, analysing changes between two dates is a crucial point. In urban environments, most changes occur along the vertical axis (with new construction or demolition of buildings) and the use of 3D data is therefore mandatory. Among them, LiDAR constitutes a valuable source of information. However, With the difficulty of processing sparse and unordered 3D point clouds, most of existing methods start by rasterizing point clouds (for example to Digital Surface Models) before using more conventional image processing tools. This implies a significant loss of information. Among existing studies dealing directly with point clouds, and to the best of our knowledge, no deep neural network-based method has been explored yet. Thus, in order to fill this gap and to test the ability of deep methods to deal with change detection and characterization of 3D point clouds, we propose a Siamese network with Kernel Point Convolution inspired by Siamese architectures that have already shown their performances on change detection in 2D images and on KPConv network which achieves high-quality results for semantic segmentation of raw 3D point clouds. We show quantitatively and qualitatively that our method outperforms by more than 25% (in terms of average Intersection over Union for classes of change) existing machine learning methods based on hand-crafted features. © 2021 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All rights reserved.",3D Change Detection; Deep Learning; Kernel Point Convolution; Point Clouds; Siamese Network; Urban Monitoring,Conference paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85115854172
Lowphansirikul C.; Kim K.-S.; Vinayaraj P.; Tuarob S.,"Lowphansirikul, Chakri (57208550806); Kim, Kvoung-Sook (57184508400); Vinayaraj, Poliyapram (54380886600); Tuarob, Suppawong (43661605700)",57208550806; 57184508400; 54380886600; 43661605700,3D Semantic Segmentation of Large-Scale Point-Clouds in Urban Areas Using Deep Learning,2019,"2019 11th International Conference on Knowledge and Smart Technology, KST 2019",,,8687813,238,243,5,11,10.1109/KST.2019.8687813,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065104515&doi=10.1109%2fKST.2019.8687813&partnerID=40&md5=e7e1ec3b5f3c62972a1e58b2b4a76682,"Point cloud is a set of points in 3D space, typically produced by a 3D scanner to capture the 3D representation of a scene. Semantic segmentation of 3D point cloud data where each point is assigned with a semantic class such as building, road, water and so on, has recently gained tremendous attention from data mining researchers and industrial practitioners. Accurate 3D-segmentation results can be used for constructing 3D scene for robotic navigation and assessing the city expansion. Dealing with point cloud data poses a huge challenge of irregular format as points are distributed irregularly unlike 2D pixel of an image or 3D voxel of a 3D model. A number of deep learning architectures have been proposed to model 3D point cloud to perform semantic segmentation. In this paper, we present a new case study of applying three novel deep learning architectures, PointNet, PointCNN and SPGraph, to an outdoor aerial survey point cloud dataset, whose features include intensity and spectral information (RGB). We then compare the results of 3D semantic segmentation from such networks in term of overall accuracy. The result shows that PointNet, PointCNN, and SPGraph achieve 83%, 72.7%, and 83.4% overall accuracy of semantic segmentation, respectively. © 2019 IEEE.",3D-Segmentation; Deep Learning; Point Cloud,Conference paper,Final,,Scopus,2-s2.0-85065104515
Chen H.; Chen W.; Wu R.; Huang Y.,"Chen, Hui (57189893488); Chen, Wanlou (57299171200); Wu, Renjie (57328702800); Huang, Yunfeng (57220060340)",57189893488; 57299171200; 57328702800; 57220060340,Plane segmentation for a building roof combining deep learning and the RANSAC method from a 3D point cloud,2021,Journal of Electronic Imaging,30,5,53022,,,,5,10.1117/1.JEI.30.5.053022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118800134&doi=10.1117%2f1.JEI.30.5.053022&partnerID=40&md5=02cad2ea594d66a04b1d266bdb032e10,"The segmentation of a point cloud on the roof plane is of great significance to the reconstruction of building models. However, the traditional segmentation methods segment the aerial point cloud of the roof, which cannot fully express the geometric structure of the roof, whereas the deep learning-based methods have problems such as too much manual annotation and training time. In this work, a plane segmentation method for a building roof based on the PointNet network combined with the random sample consensus (RANSAC) algorithm is proposed to directly segment the whole point cloud of the building, but it is not limited to the point cloud of the roof. With the proposed framework, the roof part is extracted from the building by an improved PointNet network, and then the roof semantic point cloud is segmented by the RANSAC algorithm to complete the roof extraction. Based on the experimental results gained from multiple building point clouds, it is shown that the proposed method achieves the segmentation of a roof on most multi-plane roof building point clouds and that it has strong practical value. © 2021 SPIE and IS&T.",3D point cloud; building roof; deep learning; plane segmentation,Article,Final,,Scopus,2-s2.0-85118800134
Chowdhury A.; Pattnaik N.; Ray A.; Chakravarty S.; Chakravarty T.; Pal A.,"Chowdhury, Arijit (56077144700); Pattnaik, Naibedya (58093930500); Ray, Arindam (57640734800); Chakravarty, Soumya (57616857500); Chakravarty, Tapas (55894496700); Pal, Arpan (57203638167)",56077144700; 58093930500; 57640734800; 57616857500; 55894496700; 57203638167,Unobtrusive People Identification and Tracking Using Radar Point Clouds,2023,IEEE Sensors Letters,7,12,6009104,1,4,3,0,10.1109/LSENS.2023.3328794,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177188832&doi=10.1109%2fLSENS.2023.3328794&partnerID=40&md5=f4dd5707b9c5d93743463606a913f515,"Identification of people in closed spaces is an indispensable requirement in modern smart home spaces. Existing recognition methods that utilize vision sensors, such as cameras, cannot be used for this purpose because of their privacy-invasive sensing characteristics. In this letter, we propose a method for unobtrusive identification and tracking of people by capturing their unique gait pattern in a closed space using point clouds generated from commercially available frequency modulated continuous wave radars. We primarily focus on handling the nonlinearity due to the variation of the subject's distance from the radar by augmenting the point clouds with novel height surface maps that are generated individually for every person. We build a two-level feature generation system on top of these point clouds to uniquely identify them. We also attempt identification using a blend of these height surface maps and existing point cloud processing architectures, such as PointNet and PointNet++. The average precision and recall for all seven subjects tested were $79.28\%(\pm 4.9)$ and $80.23\%(\pm 9.8)$. Finally, the proposed method augments the height surface maps with the PointNet architecture and utilizes majority voting scheme for people identification. It provides an accuracy above 90%, which indicates the efficiency of our implemented solution.  © 2017 IEEE.",frequency modulated continuous wave (FMCW) radar; gait; person identification; point clouds; PointNet; PointNet++; Sensor applications,Article,Final,,Scopus,2-s2.0-85177188832
Pierdicca R.; Paolanti M.; Matrone F.; Martini M.; Morbidoni C.; Malinverni E.S.; Frontoni E.; Lingua A.M.,"Pierdicca, Roberto (56460209100); Paolanti, Marina (57188734162); Matrone, Francesca (57195330111); Martini, Massimo (57209009649); Morbidoni, Christian (15136812700); Malinverni, Eva Savina (14066631000); Frontoni, Emanuele (9737451300); Lingua, Andrea Maria (6507402873)",56460209100; 57188734162; 57195330111; 57209009649; 15136812700; 14066631000; 9737451300; 6507402873,Point cloud semantic segmentation using a deep learning framework for cultural heritage,2020,Remote Sensing,12,6,1005,,,,117,10.3390/rs12061005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082303972&doi=10.3390%2frs12061005&partnerID=40&md5=9cef554c65f53e805b642276afab9f1e,"In the Digital Cultural Heritage (DCH) domain, the semantic segmentation of 3D Point Clouds with Deep Learning (DL) techniques can help to recognize historical architectural elements, at an adequate level of detail, and thus speed up the process of modeling of historical buildings for developing BIM models from survey data, referred to as HBIM (Historical Building Information Modeling). In this paper, we propose a DL framework for Point Cloud segmentation, which employs an improved DGCNN (Dynamic Graph Convolutional Neural Network) by adding meaningful features such as normal and colour. The approach has been applied to a newly collected DCH Dataset which is publicy available: ArCH (Architectural Cultural Heritage) Dataset. This dataset comprises 11 labeled points clouds, derived from the union of several single scans or from the integration of the latter with photogrammetric surveys. The involved scenes are both indoor and outdoor, with churches, chapels, cloisters, porticoes and loggias covered by a variety of vaults and beared by many different types of columns. They belong to different historical periods and different styles, in order to make the dataset the least possible uniform and homogeneous (in the repetition of the architectural elements) and the results as general as possible. The experiments yield high accuracy, demonstrating the effectiveness and suitability of the proposed approach. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Classification; Deep learning; Digital cultural heritage; Point clouds; Semantic segmentation,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85082303972
Wang B.; Wang Q.; Cheng J.C.P.; Yin C.,"Wang, Boyu (57221940953); Wang, Qian (56430161500); Cheng, Jack C.P. (57204665849); Yin, Chao (57221927168)",57221940953; 56430161500; 57204665849; 57221927168,Object verification based on deep learning point feature comparison for scan-to-BIM,2022,Automation in Construction,142,,104515,,,,9,10.1016/j.autcon.2022.104515,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135386047&doi=10.1016%2fj.autcon.2022.104515&partnerID=40&md5=62783e0ddb95684b80cd73e8043b9105,"Building information models (BIMs) have been widely adopted in current construction projects to enhance the efficiency of facility maintenance operations. As-built BIMs can reflect the actual conditions of facilities and thus as-built BIM reconstruction has shown great significance in digital twin generation, building health monitoring, facility management and urban renewal. Laser scanners are capable to capture dense 3D measurements of the environment in a fast and highly accurate way. Therefore, laser scanning data have been widely used for as-built BIM generation. Although research efforts have been made on how to automatically achieve “Scan-to-BIM”, there are still gaps from applying current solutions to real scenarios. One of the challenges is that some irrelevant point clusters may be wrongly recognized as the desired object in the detection stage. This study presents a novel object verification approach based on deep learning point feature comparison to improve the accuracy of automated BIM reconstruction process. Firstly, a KPConv-based deep neural network is developed and trained to perform 3D point feature computation. Then through comparing point features calculated for extracted point clusters and as-designed BIM generated point clouds, point feature distance maps are generated. Afterwards, to automatically analyze the generated feature distance maps, a dataset including simulated positive and negative instances is created based on ModelNet40. And a tiny neural network is established and trained on the prepared dataset to acquire ability of distinguishment. To validate the feasibility of the proposed technique, experiments were conducted on both artificial point clouds and real scan data collected in one MEP room in a water treatment work in Hong Kong. It is demonstrated that the proposed technique can successfully filter out all the false positives in the Scan-to-BIM process, improving reconstruction accuracy significantly. © 2022 Elsevier B.V.",As-built modeling; Building information model (BIM); Deep learning; LiDAR point clouds; Object verification,Article,Final,,Scopus,2-s2.0-85135386047
Widyaningrum E.; Fajari M.K.; Lindenbergh R.C.; Hahn M.,"Widyaningrum, E. (57191205020); Fajari, M.K. (57191204708); Lindenbergh, R.C. (7801611878); Hahn, M. (23492048300)",57191205020; 57191204708; 7801611878; 23492048300,TAILORED FEATURES for SEMANTIC SEGMENTATION with A DGCNN USING FREE TRAINING SAMPLES of A COLORED AIRBORNE POINT CLOUD,2020,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",43,B2,,339,346,7,3,10.5194/isprs-archives-XLIII-B2-2020-339-2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091113510&doi=10.5194%2fisprs-archives-XLIII-B2-2020-339-2020&partnerID=40&md5=6d2047cc8efc5a6fc35b5d840458005f,"Automation of 3D LiDAR point cloud processing is expected to increase the production rate of many applications including automatic map generation. Fast development on high-end hardware has boosted the expansion of deep learning research for 3D classification and segmentation. However, deep learning requires large amount of high quality training samples. The generation of training samples for accurate classification results, especially for airborne point cloud data, is still problematic. Moreover, which customized features should be used best for segmenting airborne point cloud data is still unclear. This paper proposes semi-automatic point cloud labelling and examines the potential of combining different tailor-made features for pointwise semantic segmentation of an airborne point cloud. We implement a Dynamic Graph CNN (DGCNN) approach to classify airborne point cloud data into four land cover classes: bare-land, trees, buildings and roads. The DGCNN architecture is chosen as this network relates two approaches, PointNet and graph CNNs, to exploit the geometric relationships between points. For experiments, we train an airborne point cloud and co-aligned orthophoto of the Surabaya city area of Indonesia to DGCNN using three different tailor-made feature combinations: points with RGB (Red, Green, Blue) color, points with original LiDAR features (Intensity, Return number, Number of returns) so-called IRN, and points with two spectral colors and Intensity (Red, Green, Intensity) so-called RGI. The overall accuracy of the testing area indicates that using RGB information gives the best segmentation results of 81.05% while IRN and RGI gives accuracy values of 76.13%, and 79.81%, respectively. © 2020 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives.",aerial photos; Airborne point cloud; DGCNN; feature combinations; semantic segmentation,Conference paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85091113510
Xiu H.; Liu X.; Wang W.; Kim K.-S.; Shinohara T.; Chang Q.; Matsuoka M.,"Xiu, Haoyi (57215270239); Liu, Xin (56948501900); Wang, Weimin (57213601132); Kim, Kyoung-Sook (57184508400); Shinohara, Takayuki (57215280854); Chang, Qiong (57203124645); Matsuoka, Masashi (7401543073)",57215270239; 56948501900; 57213601132; 57184508400; 57215280854; 57203124645; 7401543073,DS-Net: A dedicated approach for collapsed building detection from post-event airborne point clouds,2023,International Journal of Applied Earth Observation and Geoinformation,116,,103150,,,,4,10.1016/j.jag.2022.103150,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143810575&doi=10.1016%2fj.jag.2022.103150&partnerID=40&md5=a570f52c56ca5fde3ec439240fee36cf,"Collapsed buildings should be detected immediately after earthquakes for humanitarian assistance and post-disaster recovery. Automatic collapsed building detection using deep learning has recently become increasingly popular because of its superior ability to obtain discriminative feature representations. Among various types of data, airborne 3D point clouds are especially useful for detecting collapsed buildings as they precisely record the height information of buildings. However, existing methods are based on the universal point cloud analysis technology that does not explicitly consider the nature of building damage. In this study, we propose Damage-Sensitive Network (DS-Net), a dedicated approach for collapsed building detection. The core of DS-Net is Laplacian Unit (LU), a simple yet effective module for 3D point clouds designed to enhance the feature representation of the damaged part to facilitate collapsed building detection. We perform extensive experiments and demonstrate that DS-Net achieves superior performance compared with existing methods. In particular, a detailed comparison of DS-Net with PointNet++, the standard network on which DS-Net's design is based, found that DS-Net provides an 8.3% gain in precision, 3.0% gain in recall, and 6.4% gain in IoU over PointNet++ in detecting collapsed buildings. Moreover, it is verified that the detection performance can be further enhanced with increased computational resources. Qualitative analyses reveal that DS-Net excels at detecting damage manifested as roof deformations, debris, and inclinations. In addition, DS-Net produces smoother predictions with sharper boundaries compared to the baseline due to the adaptive nature of LUs. Furthermore, a visual explanation analysis based on Grad-CAM is performed to analyze how DS-Net understands building damage. The result suggests that DS-Net can accurately locate varieties of building damage. © 2022 The Author(s)",3D deep learning; Airborne 3D point clouds; Building damage; Collapsed building; Discrete Laplacian; Earthquake,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85143810575
Shen Z.; Sun Y.; Lodge T.P.; Siepmann J.I.,"Shen, Zhengyuan (57209502749); Sun, Yangzesheng (57208400320); Lodge, Timothy P. (7103096958); Siepmann, J. Ilja (35458526300)",57209502749; 57208400320; 7103096958; 35458526300,Development of a PointNet for Detecting Morphologies of Self-Assembled Block Oligomers in Atomistic Simulations,2021,Journal of Physical Chemistry B,125,20,,5275,5284,9,6,10.1021/acs.jpcb.1c02389,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106392508&doi=10.1021%2facs.jpcb.1c02389&partnerID=40&md5=9932e6e865a68cd2af8941554d918043,"Molecular simulations with atomistic or coarse-grained force fields are a powerful approach for understanding and predicting the self-assembly phase behavior of complex molecules. Amphiphiles, block oligomers, and block polymers can form mesophases with different ordered morphologies describing the spatial distribution of the blocks, but entirely amorphous nature for local packing and chain conformation. Screening block oligomer chemistry and architecture through molecular simulations to find promising candidates for functional materials is aided by effective and straightforward morphology identification techniques. Capturing 3-dimensional periodic structures, such as ordered network morphologies, is hampered by the requirement that the number of molecules in the simulated system and the shape of the periodic simulation box need to be commensurate with those of the resulting network phase. Common strategies for structure identification include structure factors and order parameters, but these fail to identify imperfect structures in simulations with incorrect system sizes. Building upon pioneering work by DeFever et al. [Chem. Sci. 2019, 10, 7503-7515] who implemented a PointNet (i.e., a neural network designed for computer vision applications using point clouds) to detect local structure in simulations of single-bead particles and water molecules, we present a PointNet for detection of nonlocal ordered morphologies of complex block oligomers. Our PointNet was trained using atomic coordinates from molecular dynamics simulation trajectories and synthetic point clouds for ordered network morphologies that were absent from previous simulations. In contrast to prior work on simple molecules, we observe that large point clouds with 1000 or more points are needed for the more complex block oligomers. The trained PointNet model achieves an accuracy as high as 0.99 for globally ordered morphologies formed by linear diblock, linear triblock, and 3-arm and 4-arm star-block oligomers, and it also allows for the discovery of emerging ordered patterns from nonequilibrium systems.  © ",,Article,Final,,Scopus,2-s2.0-85106392508
Shao W.; Kakizaki K.; Araki S.; Mukai T.,"Shao, Wanpeng (57461744500); Kakizaki, Ken'Ichi (36876160100); Araki, Shunsuke (7402410948); Mukai, Tomohisa (42661692100)",57461744500; 36876160100; 7402410948; 42661692100,Damage Detection of the RC Building in TLS Point Clouds Using 3D Deep Neural Network PointNet++,2021,"Proceedings - 23rd IEEE International Symposium on Multimedia, ISM 2021",,,,39,42,3,3,10.1109/ISM52913.2021.00015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125018419&doi=10.1109%2fISM52913.2021.00015&partnerID=40&md5=67ba3e31b6ba79c9e6e6b9493afe85df,"We are working on a research project to evaluate the safety and structure of reinforced concrete buildings damaged by earthquakes using point cloud data acquired by a terrestrial laser scanner. We propose a framework for damage analysis as a classification problem that divides a building in point clouds into small 3D voxel grids and determines which voxels are damaged, instead of detecting the damaged parts from the point cloud of the whole building. Our framework is divided into three steps: First, the damaged building in point clouds is divided into small 3d voxel grids. Second, every voxel is fed into the deep neural network for damage classification. As a deep neural network to classify the voxel grids, we used PointNet++. Finally, the original damage map is refined by a simple cluster analysis. After post-processing, the recall reaches 0.929. That is, 92.9% of damage portions are correctly detected although the damage map still contains some FPs.  © 2021 IEEE.",damage detection; earthquake; point clouds; PointNet++; reinforced concrete building; terrestrial laser scanner,Conference paper,Final,,Scopus,2-s2.0-85125018419
Koo B.; Jung R.; Yu Y.; Kim I.,"Koo, Bonsang (7101738312); Jung, Raekyu (57219890755); Yu, Youngsu (57204916978); Kim, Inhan (7404143715)",7101738312; 57219890755; 57204916978; 7404143715,A geometric deep learning approach for checking element-to-entity mappings in infrastructure building information models,2021,Journal of Computational Design and Engineering,8,1,,239,250,11,20,10.1093/jcde/qwaa075,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100823731&doi=10.1093%2fjcde%2fqwaa075&partnerID=40&md5=b3c7ac5f3d394a7761935210d74255b6,"Data interoperability between domain-specific applications is a key prerequisite for building information modeling (BIM) to solidify its position as a central medium for collaboration and information sharing in the construction industry. The Industry Foundation Classes (IFC) provides an open and neutral data format to standardize data exchanges in BIM, but is often exposed to data loss and misclassifications. Concretely, errors in mappings between BIM elements and IFC entities may occur due to manual omissions or the lack of awareness of the IFC schema itself, which is broadly defined and highly complex. This study explored the use of geometric deep learning models to classify infrastructure BIM elements, with the ultimate goal of automating the prechecking of BIM-to-IFC mappings. Two models with proven classification performance, Multi-View Convolutional Neural Network (MVCNN) and PointNet, were trained and tested to classify 10 types of commonly used BIM elements in road infrastructure, using a dataset of 1496 3D models. Results revealed MVCNN as the superior model with ACC and F1 score values of 0.98 and 0.98, compared with PointNet's corresponding values of 0.83 and 0.87, respectively. MVCNN, which employs multiple images to learn the features of a 3D artifact, was able to discern subtle differences in their shapes and geometry. PointNet seems to lose the granularity of the shapes, as it uses points partially selected from point clouds.  © 2020 The Author(s) 2020. Published by Oxford University Press on behalf of the Society for Computational Design and Engineering.",BIM; geometric deep learning; IFC; infrastructure; semantic integrity,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85100823731
Shin Y.-H.; Son K.-W.; Lee D.-C.,"Shin, Young-Ha (57219247571); Son, Kyung-Wahn (57455055800); Lee, Dong-Cheon (36138668700)",57219247571; 57455055800; 36138668700,Semantic Segmentation and Building Extraction from Airborne LiDAR Data with Multiple Return Using PointNet++,2022,Applied Sciences (Switzerland),12,4,1975,,,,7,10.3390/app12041975,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124747549&doi=10.3390%2fapp12041975&partnerID=40&md5=1d22a12ae9effd1b42eef7589a602456,"Light detection and ranging (LiDAR) data of 3D point clouds acquired from laser sensors is a crucial form of geospatial data for recognition of complex objects since LiDAR data provides geometric information in terms of 3D coordinates with additional attributes such as intensity and multiple returns. In this paper, we focused on utilizing multiple returns in the training data for semantic segmentation, in particular building extraction using PointNet++. PointNet++ is known as one of the efficient and robust deep learning (DL) models for processing 3D point clouds. On most building boundaries, two returns of the laser pulse occur. The experimental results demonstrated that the proposed approach could improve building extraction by adding two returns to the training datasets. Specifically, the recall value of the predicted building boundaries for the test data was improved from 0.7417 to 0.7948 for the best case. However, no significant improvement was achieved for the new data because the new data had relatively lower point density compared to the training and test data. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Deep learning; LiDAR data; Multiple return; Point clouds; Semantic segmentation,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85124747549
Liu C.; Hu Y.; Li Z.; Xu J.; Han Z.; Guo J.,"Liu, Chun (55680754700); Hu, Yaohui (57223000500); Li, Zheng (57188693624); Xu, Junkui (57305991100); Han, Zhigang (56539137300); Guo, Jianzhong (56161125200)",55680754700; 57223000500; 57188693624; 57305991100; 56539137300; 56161125200,Triangleconv: A deep point convolutional network for recognizing building shapes in map space,2021,ISPRS International Journal of Geo-Information,10,10,687,,,,11,10.3390/ijgi10100687,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117728241&doi=10.3390%2fijgi10100687&partnerID=40&md5=e0c88df043b8fe77541c52a051a5e54e,"The classification and recognition of the shapes of buildings in map space play an important role in spatial cognition, cartographic generalization, and map updating. As buildings in map space are often represented as the vector data, research was conducted to learn the feature representations of the buildings and recognize their shapes based on graph neural networks. Due to the principles of graph neural networks, it is necessary to construct a graph to represent the adjacency relationships between the points (i.e., the vertices of the polygons shaping the buildings), and extract a list of geometric features for each point. This paper proposes a deep point convolutional network to recognize building shapes, which executes the convolution directly on the points of the buildings without constructing the graphs and extracting the geometric features of the points. A new convolution operator named TriangleConv was designed to learn the feature representations of each point by aggregating the features of the point and the local triangle constructed by the point and its two adjacency points. The proposed method was evaluated and compared with related methods based on a dataset consisting of 5010 vector buildings. In terms of accuracy, macro-precision, macro-recall, and macro-F1, the results show that the proposed method has comparable performance with typical graph neural networks of GCN, GAT, and GraphSAGE, and point cloud neural networks of PointNet, PointNet++, and DGCNN in the task of recognizing and classifying building shapes in map space. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Map space; Point convolution; Shape classification; Shape recognition; TriangleConv,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85117728241
Gamal A.; Husodo A.Y.; Jati G.; Alhamidi M.R.; Ma'Sum M.A.; Ardhianto R.; Jatmiko W.,"Gamal, Ahmad (57200131887); Husodo, Ario Yudo (53263950600); Jati, Grafika (55490339500); Alhamidi, Machmud R (57188981651); Ma'Sum, M. Anwar (57213817389); Ardhianto, Ronni (57200085262); Jatmiko, Wisnu (8568432600)",57200131887; 53263950600; 55490339500; 57188981651; 57213817389; 57200085262; 8568432600,Outdoor LiDAR Point Cloud Building Segmentation: Progress and Challenge,2021,"2021 International Conference on Advanced Computer Science and Information Systems, ICACSIS 2021",,,,,,,0,10.1109/ICACSIS53237.2021.9631345,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123854696&doi=10.1109%2fICACSIS53237.2021.9631345&partnerID=40&md5=4676ceefca60453776e7d2a48400b3f8,"The demand for 3D modeling using LiDAR as the primary source for observing, planning, and managing urban areas has increased. Using LiDAR data improves the accuracy of the modeling so that it can be used for policy determination and infrastructure planning. Various kinds of research on LiDAR data have been carried out, one of which is indoor and outdoor LiDAR segmentation. For outdoor cases, LiDAR data can be obtained from two points of view, namely ground view and aerial view. In this paper, we discuss the advancements and challenges of LiDAR 3D modeling in building segmentation that we have carried out. We collect LiDAR data with unmanned aerial vehicles. We use several algorithms such as PointNet and the Dynamic Graph Convolutional Neural Network variations to group structures from LiDAR data. The result is that the proposed method can segment buildings, surfaces, and vegetation well. The average accuracy produced for the Kupang and Depok datasets reaches 70%-80%. © 2021 IEEE.",3D Modeling; Building Segmentation; Dynamic Graph Convolutional Neural Network; LiDAR; PointNet,Conference paper,Final,,Scopus,2-s2.0-85123854696
Mao Y.; Chen K.; Diao W.; Sun X.; Lu X.; Fu K.; Weinmann M.,"Mao, Yongqiang (57563850100); Chen, Kaiqiang (57200269572); Diao, Wenhui (56816620400); Sun, Xian (34875643000); Lu, Xiaonan (57226744637); Fu, Kun (7202283802); Weinmann, Martin (55818523800)",57563850100; 57200269572; 56816620400; 34875643000; 57226744637; 7202283802; 55818523800,Beyond single receptive field: A receptive field fusion-and-stratification network for airborne laser scanning point cloud classification,2022,ISPRS Journal of Photogrammetry and Remote Sensing,188,,,45,61,16,23,10.1016/j.isprsjprs.2022.03.019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127674857&doi=10.1016%2fj.isprsjprs.2022.03.019&partnerID=40&md5=84db7e9ad1c69e201d78be1aed5e3d52,"The classification of airborne laser scanning (ALS) point clouds is a critical task of remote sensing and photogrammetry fields. Although recent deep learning-based methods have achieved satisfactory performance, they have ignored the unicity of the receptive field, which makes the ALS point cloud classification remain challenging for the distinguishment of the areas with complex structures and extreme scale variations. In this article, for the objective of configuring multi-receptive field features, we propose a novel receptive field fusion-and-stratification network (RFFS-Net). With a novel dilated graph convolution (DGConv) and its extension annular dilated convolution (ADConv) as basic building blocks, the receptive field fusion process is implemented with the dilated and annular graph fusion (DAGFusion) module, which obtains multi-receptive field feature representation through capturing dilated and annular graphs with various receptive regions. The stratification of the receptive fields with point sets of different resolutions as the calculation bases is performed with Multi-level Decoders nested in RFFS-Net and driven by the multi-level receptive field aggregation loss (MRFALoss) to drive the network to learn in the direction of the supervision labels with different resolutions. With receptive field fusion-and-stratification, RFFS-Net is more adaptable to the classification of regions with complex structures and extreme scale variations in large-scale ALS point clouds. Evaluated on the ISPRS Vaihingen 3D dataset, our RFFS-Net significantly outperforms the baseline (i.e. PointConv) approach by 5.3% on mF1 and 5.4% on mIoU, accomplishing an overall accuracy of 82.1%, an mF1 of 71.6%, and an mIoU of 58.2%. The experiments show that our RFFS-Net achieves a new state-of-the-art classification performance on powerline, car, and fence classes. Furthermore, experiments on the LASDU dataset and the 2019 IEEE-GRSS Data Fusion Contest dataset show that RFFS-Net achieves a new state-of-the-art classification performance. The code is available at github.com/WingkeungM/RFFS-Net. © 2022 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Airborne laser scanning; Classification; Deep learning; Dilated graph convolution; Multi-scale receptive fields; Point cloud,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85127674857
Hu C.; Zhang Y.; Xia G.; Liu X.; Ma X.,"Hu, Chunmei (56286854500); Zhang, Yunhui (58177375400); Xia, Guofang (57202046543); Liu, Xi (57416267800); Ma, Xinjian (57742575700)",56286854500; 58177375400; 57202046543; 57416267800; 57742575700,Automatic Classification of Ancient Building Components Based on PointNet++,2022,"Proceedings - 2022 International Conference on Artificial Intelligence, Information Processing and Cloud Computing, AIIPCC 2022",,,,99,103,4,0,10.1109/AIIPCC57291.2022.00029,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152123513&doi=10.1109%2fAIIPCC57291.2022.00029&partnerID=40&md5=3195d0065919be3d840f9b529af5d59d,"In order to preserve the Forbidden City buildings., a dataset of wooden components of ancient buildings based on the point cloud of ancient buildings., combining the current state model with the standard model., is proposed., and the improved PointNet++ algorithm for point cloud deep learning is applied to train the dataset., and the training strategy is optimised with Adam W and cross-entropy loss function with label smoothing, and the PointNet++ network is found to be applicable through comparative experiments The dataset production method is found to be suitable for PointNet++ network through comparison experiments. The large number of samples required for model training is difficult and costly to collect, limiting its widespread use. The improved PointNet++ has better segmentation accuracy than the original method, and is able to automatically segment the 3D point clouds of wooden elements of ancient buildings using a small dataset containing 70 rooms and 3198 samples. The experiments demonstrate that the segmentation accuracy of this research method has reached 87.79%, which verifies the effectiveness of the improved algorithm, and the segmentation results can provide favourable data support for the digital conservation of ancient buildings. © 2022 IEEE.",3D point cloud segmentation; Deep learning; Forbidden City architecture; PointNet++; Wooden components,Conference paper,Final,,Scopus,2-s2.0-85152123513
Lee J.S.; Park J.; Ryu Y.-M.,"Lee, Jun S. (57219322809); Park, Jeongjun (57196405219); Ryu, Young-Moo (57208264065)",57219322809; 57196405219; 57208264065,Semantic segmentation of bridge components based on hierarchical point cloud model,2021,Automation in Construction,130,,103847,,,,27,10.1016/j.autcon.2021.103847,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111244902&doi=10.1016%2fj.autcon.2021.103847&partnerID=40&md5=ee009ad62c01831a85a3559acf8afe79,"Geometric information such as the volumetric dimensions and type of a bridge can be retrieved by means of a terrestrial laser scanner, and the point cloud (PC) data thus obtained can be used to build 3-dimensional (3D) objects such as bridge components in the Building Information Modeling (BIM) framework. For modeling of PC data, PointNet (Qi et al., 2018) and a graph-based convolutional neural network (GCNN) model known as dynamic GCNN (DGCNN; Wang et al., 2019) have been widely employed. In this study, a graph-based hierarchical DGCNN (HGCNN) model is proposed for more accurate and realistic representation of railway bridges having electric poles. The model obtains detailed local features by incrementally considering neighboring points while the total number of neighbors remains the same. Field application reveals that the proposed HGCNN model can represent tall components such as electric poles more precisely, while the overall accuracy of semantic segmentation is dominated by bulky components such as decks, so that the differences among the models (PointNet, DGCNN and HGCNN) are not significant. Specifically, the recall and intersection over union (IoU) rate of the electric pole were improved by about 3% when using the proposed model. A few parametric studies were also performed, and it was demonstrated that the proposed model with its expanded local features provides more precise information near the object boundaries. © 2021 Elsevier B.V.",Bridge components; Hierarchical graph neural network; Point cloud; Semantic segmentation,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85111244902
Zhai R.; Zou J.; He Y.; Meng L.,"Zhai, Ruoming (57538905400); Zou, Jingui (55222611800); He, Yifeng (57206937039); Meng, Liyuan (57190229367)",57538905400; 55222611800; 57206937039; 57190229367,IAGC: Interactive Attention Graph Convolution Network for Semantic Segmentation of Point Clouds in Building Indoor Environment,2022,ISPRS International Journal of Geo-Information,11,3,181,,,,1,10.3390/ijgi11030181,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126642105&doi=10.3390%2fijgi11030181&partnerID=40&md5=10c425b60f14150d1d22df12b18ec89b,"Point-based networks have been widely used in the semantic segmentation of point clouds owing to the powerful 3D convolution neural network (CNN) baseline. Most of the current methods resort to intermediate regular representations for reorganizing the structure of point clouds for 3D CNN networks, but they may neglect the inherent contextual information. In our work, we focus on capturing discriminative features with the interactive attention mechanism and propose a novel method consisting of the regional simplified dual attention network and global graph convolution network. Firstly, we cluster homogeneous points into superpoints and construct a superpoint graph to effectively reduce the computation complexity and greatly maintain spatial topological relations among superpoints. Secondly, we integrate cross-position attention and cross-channel attention into a single head attention module and design a novel interactive attention gating (IAG)-based multi-layer perceptron (MLP) network (IAG–MLP), which is utilized for the expansion of the receptive field and augmentation of discriminative features in local embeddings. Afterwards, the combina-tion of stacked IAG–MLP blocks and the global graph convolution network, called IAGC, is proposed to learn high-dimensional local features in superpoints and progressively update these local embeddings with the recurrent neural network (RNN) network. Our proposed framework is eval-uated on three indoor open benchmarks, and the 6-fold cross-validation results of the S3DIS dataset show that the local IAG–MLP network brings about 1% and 6.1% improvement in overall accuracy (OA) and mean class intersection-over-union (mIoU), respectively, compared with the PointNet local network. Furthermore, our IAGC network outperforms other CNN-based approaches in the ScanNet V2 dataset by at least 7.9% in mIoU. The experimental results indicate that the proposed method can better capture contextual information and achieve competitive overall performance in the semantic segmentation task. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Deep learning; Graph convolution; Point cloud; Self-attention mechanism; Semantic segmentation,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85126642105
Zhang Y.; Müller S.; Stephan B.; Gross H.-M.; Notni G.,"Zhang, Yan (57218471066); Müller, Steffen (57199400995); Stephan, Benedict (57235224200); Gross, Horst-Michael (7202668837); Notni, Gunther (7004204934)",57218471066; 57199400995; 57235224200; 7202668837; 7004204934,Point cloud hand–object segmentation using multimodal imaging with thermal and color data for safe robotic object handover,2021,Sensors,21,16,5676,,,,7,10.3390/s21165676,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113710202&doi=10.3390%2fs21165676&partnerID=40&md5=eb11aab08414dcd6f4f362a3981035c2,"This paper presents an application of neural networks operating on multimodal 3D data (3D point cloud, RGB, thermal) to effectively and precisely segment human hands and objects held in hand to realize a safe human–robot object handover. We discuss the problems encountered in building a multimodal sensor system, while the focus is on the calibration and alignment of a set of cameras including RGB, thermal, and NIR cameras. We propose the use of a copper–plastic chessboard calibration target with an internal active light source (near-infrared and visible light). By brief heating, the calibration target could be simultaneously and legibly captured by all cameras. Based on the multimodal dataset captured by our sensor system, PointNet, PointNet++, and RandLA-Net are utilized to verify the effectiveness of applying multimodal point cloud data for hand–object segmentation. These networks were trained on various data modes (XYZ, XYZ-T, XYZ-RGB, and XYZ-RGB-T). The experimental results show a significant improvement in the segmentation performance of XYZ-RGB-T (mean Intersection over Union: 82.8% by RandLA-Net) compared with the other three modes (77.3% by XYZ-RGB, 35.7% by XYZ-T, 35.7% by XYZ), in which it is worth mentioning that the Intersection over Union for the single class of hand achieves 92.6%. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Deep neural network; Hand segmentation; Multimodal imaging; Point cloud segmentation; Thermal,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85113710202
Ji Y.; Dong Y.; Hou M.; Qi Y.; Li A.,"Ji, Y. (57219031830); Dong, Y. (57194640723); Hou, M. (12773745000); Qi, Y. (57215818562); Li, A. (57204331975)",57219031830; 57194640723; 12773745000; 57215818562; 57204331975,An extraction method for roof point cloud of ancient building using deep learning framework,2021,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",46,M-1-2021,,321,327,6,1,10.5194/isprs-Archives-XLVI-M-1-2021-321-2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118569784&doi=10.5194%2fisprs-Archives-XLVI-M-1-2021-321-2021&partnerID=40&md5=efc92107e3b55e35830767fd1dc33acb,"Chinese ancient architecture is a valuable heritage wealth, especially for roof that reflects the construction age, structural features and cultural connotation. Point cloud data, as a flexible representation with characteristics of fast, precise, non-contact, plays a crucial role in a variety of applications for ancient architectural heritage, such as 3D fine reconstruction, HBIM, disaster monitoring etc. However, there are still many limitations in data editing tasks that need to be worked out manually, which is time-consuming, labor-intensive and error-prone. In recent years, the theoretical advance on deep learning has stimulated the development of various domains, and digital heritage is not in exception. Whenever, deep learning algorithm need to consume a huge amount of labeled date to achieve the purpose for segmentation, resulting a actuality that high labor costs also be acquired. In this paper, inspired by the architectural style similarity between mimetic model and real building, we proposed a method supported by deep learning, which aims to give a solution for the point cloud automatic extraction of roof structure. Firstly, to generate real point cloud, Baoguang Temple, unmanned Aerial Vehicle (UAV) is presented to obtain image collections that are subsequently processed by reconstruction technology. Secondly, a modified Dynamic Graph Convolutional Neural Network (DGCNN) which can learn local features with taking advantage of an edge attention convolution is trained using simulated data and additional attributes of geometric attributes. The mimetic data is sampled from 3DMAX model surface. Finally, we try to extract roof structure of ancient building from real point clouds scenes utilizing the trained model. The experimental results show that the proposed method can extract the rooftop structure from real scene of Baoguang, which illustrates not only effectiveness of approach but also a fact that the simulated source perform potential value when real point cloud datasets are scarce. © 2021 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All Rights Reserved.",Ancient Building; Deep Learning; DGCNN; Point Cloud Segmentation; Roof Extraction,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85118569784
Wicaksono S.B.; Wibisono A.; Jatmiko W.; Gamal A.; Wisesa H.A.,"Wicaksono, Satria Bagus (57215319937); Wibisono, Ari (55625531300); Jatmiko, Wisnu (8568432600); Gamal, Ahmad (57200131887); Wisesa, Hanif Arief (57189234078)",57215319937; 55625531300; 8568432600; 57200131887; 57189234078,Semantic Segmentation on LiDAR Point Cloud in Urban Area using Deep Learning,2019,"2019 International Workshop on Big Data and Information Security, IWBIS 2019",,,8935882,63,66,3,8,10.1109/IWBIS.2019.8935882,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078035596&doi=10.1109%2fIWBIS.2019.8935882&partnerID=40&md5=5e8388307a1535754fa162d874e60b55,"Semantic segmentation in an urban area can be utilized to differentiate between various objects on LiDAR point cloud data. This research aims to distinguish between buildings object and non-buildings object by performing semantic segmentation on the LiDAR point cloud data. A deep learning method has been proven to achieve state-of-art performance on semantic segmentation task. Dynamic Graph Convolutional Neural Network (DGCNN) is used to perform semantic segmentation in this research. Two datasets from two different regions are used to perform semantic segmentation. The first dataset is retrieved from Margonda region in Depok, Indonesia, and the second dataset is retrieved from Dublin region in Ireland. The experiment shows that the deep learning method is capable of doing semantic segmentation on LiDAR point cloud data. When tested the first dataset achieved accuracy of 86,3% and mean IoU of 70,3%. The second dataset achieved accuracy of 81,9% and mean IoU of 65,2%. © 2019 IEEE.",Deep Learning; LiDAR; Point cloud; Semantic segmentation,Conference paper,Final,,Scopus,2-s2.0-85078035596
Xiong Z.; Wang T.,"Xiong, Zhaoyang (57222657552); Wang, Ting (57222653369)",57222657552; 57222653369,Research on BIM Reconstruction Method Using Semantic Segmentation Point Cloud Data Based on PointNet,2021,IOP Conference Series: Earth and Environmental Science,719,2,22042,,,,5,10.1088/1755-1315/719/2/022042,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104772313&doi=10.1088%2f1755-1315%2f719%2f2%2f022042&partnerID=40&md5=ad7bd0571e5651669191e90fd011919c,"As the construction industry is shifting from the construction of new buildings to the maintenance and use of existing buildings in recent years, the demand for automated building information models (BIM) creation is increasing. This paper uses the deep learning network PointNet to perform semantic segmentation on the public S3DIS point cloud data set, which means to assign the same type of point cloud building components in the data set to the same label, and the bounding box algorithm is been used to obtain the outer contour parameters of the segmented point cloud building components. Finally, the Dynamo, which is one of the Revit plug-in, is used to perform parametric modeling according to the obtained parameters, and generates the BIM corresponding to the point cloud data set. The experimental results show that the method proposed in this paper can complete the parametric creation of BIM with high completeness based on the efficient segmentation of point clouds. © Published under licence by IOP Publishing Ltd.",Building Information Model; deep learning; dynamo parametric automatic modeling; point cloud,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85104772313
Bao R.; Palaniappan K.; Zhao Y.; Seetharaman G.; Zeng W.,"Bao, Rina (57218937647); Palaniappan, Kannappan (6701784534); Zhao, Yunxin (57203236668); Seetharaman, Guna (6701776440); Zeng, Wenjun (58083194000)",57218937647; 6701784534; 57203236668; 6701776440; 58083194000,GLSNet: Global and Local Streams Network for 3D Point Cloud Classification,2019,Proceedings - Applied Imagery Pattern Recognition Workshop,2019-October,,9174587,,,,5,10.1109/AIPR47015.2019.9174587,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090853143&doi=10.1109%2fAIPR47015.2019.9174587&partnerID=40&md5=fe1cc23bfa836e19280446a6fc983acf,"We propose a novel deep architecture for semantic labeling of 3D point clouds referred to as Global and Local Streams Network (GLSNet) which is designed to capture both global and local structures and contextual information for large scale 3D point cloud classification. Our GLSNet tackles a hard problem-large differences of object sizes in large-scale point cloud segmentation including extremely large objects like water, and small objects like buildings and trees, and we design a two-branch deep network architecture to decompose the complex problem to separate processing problems at global and local scales and then fuse their predictions. GLSNet combines the strength of Submanifold Sparse Convolutional Network [1] for learning global structure with the strength of PointNet++ [2] for incorporating local information.The first branch of GLSNet processes a full point cloud in the global stream, and it captures long range information about the geometric structure by using a U-Net structured Submanifold Sparse Convolutional Network (SSCN-U) architecture. The second branch of GLSNet processes a point cloud in the local stream, and it partitions 3D points into slices and processes one slice of the cloud at a time by using the PointNet ++ architecture. The two streams of information are fused by max pooling over their classification prediction vectors. Our results on the IEEE GRSS Data Fusion Contest Urban Semantic 3D, Track 4 (DFT4) [3] [4] [5] point cloud classification dataset have shown that GLSNet achieved performance gains of almost 4% in mIOU and 1% in overall accuracy over the individual streams on the held-back testing dataset.  © 2019 IEEE.",3D semantic segmentation; Global and local streams; Point clouds,Conference paper,Final,,Scopus,2-s2.0-85090853143
Zhang H.; Wang T.,"Zhang, Heng (58040130700); Wang, Tianyu (57211063379)",58040130700; 57211063379,An Efficient Method for Producing Deep Learning Point Cloud Datasets based on BIM 3D Model and Computer Simulation,2022,Proceedings of SPIE - The International Society for Optical Engineering,12474,,124740Z,,,,0,10.1117/12.2653608,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145433380&doi=10.1117%2f12.2653608&partnerID=40&md5=d7fece2f5f6ec86c0e7763cd981df706,"Currently, 3D deep learning based on point cloud data has become a research hotspot in the field of computer vision. However, the high cost of acquiring point cloud data, the tedious process of processing and labeling, and the scarcity of high-quality and suitable datasets have been the prominent problems faced by researchers. In this paper, we propose a method to quickly produce point cloud dataset based on BIM 3D model and computer simulation technology, including the steps of classifying and labeling BIM models, converting 3D object data formats, extracting point clouds using Pytorch3d and Open3d libraries, and improving efficiency through Revit secondary development and Dos batch processing. Finally, we demonstrate the effectiveness of the method by performing semantic segmentation experiments using Pointnet++ network and analyzed the impact of point cloud sampling density, sampling method and 3D model accuracy on the performance of virtual point cloud. As a digital twin of the real world, BIM models are a natural database with rich scenes and all kinds of elements. It is hoped that the method studied in this paper can help researchers to produce datasets applicable to their own research and provide help for the application of 3D deep learning techniques in engineering and other fields. © 2022 SPIE.",BIM; computer vision; deep learning; point cloud; synthetic dataset,Conference paper,Final,,Scopus,2-s2.0-85145433380
Shokri D.; Zaboli M.; Dolati F.; Homayouni S.,"Shokri, D. (57216336147); Zaboli, M. (57216337129); Dolati, F. (58080059600); Homayouni, S. (24070293900)",57216336147; 57216337129; 58080059600; 24070293900,POINTNET++ TRANSFER LEARNING FOR TREE EXTRACTION FROM MOBILE LIDAR POINT CLOUDS,2023,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",10,4/W1-2022,,721,727,6,0,10.5194/isprs-annals-X-4-W1-2022-721-2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146948168&doi=10.5194%2fisprs-annals-X-4-W1-2022-721-2023&partnerID=40&md5=c4e90d87fad6016f0c70a985639e6bc2,"Trees are an essential part of the natural and urban environment due to providing crucial benefits such as increasing air quality and wildlife habitats. Therefore, various remote sensing and photogrammetry technologies, including Mobile Laser Scanner (MLS), have been recently introduced for precise 3D tree mapping and modeling. The MLS provides densely 3D LiDAR point clouds from the surrounding, which results in measuring applicable information of trees like stem diameter or elevation. In this paper, a transfer learning procedure on the PointNet++ has been proposed for tree extraction. Initially, two steps of converting the MLS point clouds into same-length smaller sections and eliminating ground points have been conducted to overcome the massive volume of MLS data. The algorithm was tested on four LiDAR datasets ranging from challengeable urban environments containing multiple objects like tall buildings to railway surroundings. F1-Score accuracy was gained at around 93% and 98%, which showed the feasibility and efficiency of the proposed algorithm. Noticeably, the algorithms also measured geometrical information of extracted trees such as 2D coordinate space, height, stem diameter, and 3D boundary tree locations. © Author(s) 2023. CC BY 4.0 License.",Deep Learning Neural Network; LiDAR Point Clouds; Mobile Laser Scanner (MLS); PointNet++; Tree Extraction,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85146948168
Cao Y.; Scaioni M.,"Cao, Yuwei (57219026348); Scaioni, Marco (8261815100)",57219026348; 8261815100,3DLEB-net: Label-efficient deep learning-based semantic segmentation of building point clouds at LoD3 level,2021,Applied Sciences (Switzerland),11,19,8996,,,,10,10.3390/app11198996,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115910375&doi=10.3390%2fapp11198996&partnerID=40&md5=13abdc1063a3f06d8716011d7a2a51e8,"In current research, fully supervised Deep Learning (DL) techniques are employed to train a segmentation network to be applied to point clouds of buildings. However, training such networks requires large amounts of fine-labeled buildings’ point-cloud data, presenting a major challenge in practice because they are difficult to obtain. Consequently, the application of fully supervised DL for semantic segmentation of buildings’ point clouds at LoD3 level is severely limited. In order to reduce the number of required annotated labels, we proposed a novel label-efficient DL network that obtains per-point semantic labels of LoD3 buildings’ point clouds with limited supervision, named 3DLEB-Net. In general, it consists of two steps. The first step (Autoencoder, AE) is composed of a Dynamic Graph Convolutional Neural Network (DGCNN) encoder and a folding-based decoder. It is designed to extract discriminative global and local features from input point clouds by faithfully reconstructing them without any label. The second step is the semantic segmentation network. By supplying a small amount of task-specific supervision, a segmentation network is proposed for semantically segmenting the encoded features acquired from the pre-trained AE. Experimentally, we evaluated our approach based on the Architectural Cultural Heritage (ArCH) dataset. Compared to the fully supervised DL methods, we found that our model achieved state-of-the-art results on the unseen scenes, with only 10% of labeled training data from fully supervised methods as input. Moreover, we conducted a series of ablation studies to show the effectiveness of the design choices of our model. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",3D point cloud; Autoencoder; Label-efficient; LoD3 building; Unsupervised deep learning,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85115910375
Shen M.; Gao Y.; Qiu J.,"Shen, Meisheng (57220033009); Gao, Yan (57220039744); Qiu, Jingjun (57220032714)",57220033009; 57220039744; 57220032714,DbNet: Double-Ball Model for Processing Point Clouds,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12221 LNCS,,,313,325,12,0,10.1007/978-3-030-61864-3_27,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096560640&doi=10.1007%2f978-3-030-61864-3_27&partnerID=40&md5=b24f3c6eda185b1827aea962a9376a1f,"Learning and understanding 3D point clouds with convolutional networks is challenging due to the irregular and unordered data format. Reviewing existing network models based on PointNet[13] and PointNet++[14], they resample in different regions and explore not enough due to the irregularity and sparsity of the geometric structures. In this paper, we proposed a double-ball model embedded in the hierarchical network(DbNet) that directly extracts the features from the point clouds. This method avoids overlapping and better captures the local neighborhood geometry of each point. Double-ball model has two key steps: double-ball query and building features graph. Double-ball query avoids the resampling problem caused by the simple ball query. Building features graph takes angular features and edge features of point clouds into consideration. This method has no requirements for translation and rotation with the object. We apply it to 3D shapes classification and segmentation. And experiments on two benchmarks show that the suggested network outperforms the models based on PointNet/PointNet++ and is able to provide state of the art results. © 2020, Springer Nature Switzerland AG.",Convolutional network; Double-ball model; Point clouds,Conference paper,Final,,Scopus,2-s2.0-85096560640
Kada M.,"Kada, M. (14052416300)",14052416300,3D RECONSTRUCTION OF SIMPLE BUILDINGS FROM POINT CLOUDS USING NEURAL NETWORKS WITH CONTINUOUS CONVOLUTIONS (CONVPOINT),2022,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",48,4/W4-2022,,61,66,5,2,10.5194/isprs-archives-XLVIII-4-W4-2022-61-2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140330601&doi=10.5194%2fisprs-archives-XLVIII-4-W4-2022-61-2022&partnerID=40&md5=daa7f8dc996401e1fb042d648c70ad78,"The automatic reconstruction of 3D building models from airborne laser scanning point clouds or aerial imagery data in a model-driven fashion most often consists of a recognition of standardized building primitives with typically rectangular footprints and parameterized roof shapes based on a pre-defined collection, and a parameter estimation so that the selected primitives best fit the input data. For more complex buildings that consist of multiple parts, several such primitives need to be combined. This paper focuses on the reconstruction of such simple buildings, and explores the potential of Deep Learning by presenting a neural network architecture that takes a 3D point cloud of a single building as input and outputs the geometric information needed to construct a 3D building model in half-space representation with up to four roof faces like saddleback, hip, and pyramid roof. The proposed neural network architecture consists of a roof face segmentation module implemented with continuous convolutions as used in ConvPoint, which performs feature extraction directly from a set of 3D points, and four PointNet modules that predict from sampled subsets of the feature-enriched points the presence of four roof faces and their slopes. Trained with the RoofN3D dataset, which contains roof point segmentations and geometric information for 3D reconstruction purposes for about 118,000 simple buildings, the neural network achieves a performance of about 80% intersection over union (IoU) for roof face segmentation, 1.8° mean absolute error (MAE) for roof slope angles, and 95% overall accuracy (OA) for predicting the presence of faces. Copyright © 2022 M. Kada.",3D; Buildings; City Modelling; Deep Learning; Neural Networks; Point Clouds; Reconstruction,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85140330601
Cennamo A.; Kaestner F.; Kummert A.,"Cennamo, Alessandro (57219118790); Kaestner, Florian (8646602200); Kummert, Anton (7003293794)",57219118790; 8646602200; 7003293794,A Neural Network Based System for Efficient Semantic Segmentation of Radar Point Clouds,2021,Neural Processing Letters,53,5,,3217,3235,18,3,10.1007/s11063-021-10544-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107386926&doi=10.1007%2fs11063-021-10544-4&partnerID=40&md5=897dfcb3dbdcafa80208b183cd8c6141,"The last decade has witnessed important advancements in the field of computer vision and scene understanding, enabling applications such us autonomous vehicles. Radar is a commonly adopted sensor in automotive industry, but its suitability to machine learning techniques still remains an open question. In this work, we propose a neural network (NN) based solution to efficiently process radar data. We introduce RadarPCNN, an architecture specifically designed for performing semantic segmentation on radar point clouds. It uses PointNet+ + as a building-block—enhancing the sampling stage with mean-shift—and an attention mechanism to fuse information. Additionally, we propose a machine learning radar pre-processing module that confers the network the ability to learn from radar features. We show that our solutions are effective, yielding superior performance than the state-of-the-art. © 2021, The Author(s).",Autonomous vehicle; Neural network; Point clouds; Radar,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85107386926
Su S.; Nakano K.; Wakabayashi K.,"Su, S. (57219023107); Nakano, K. (55290431900); Wakabayashi, K. (57742675600)",57219023107; 55290431900; 57742675600,BUILDING DETECTION FROM AERIAL LIDAR POINT CLOUD USING DEEP LEARNING,2022,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",43,B2-2022,,291,296,5,0,10.5194/isprs-archives-XLIII-B2-2022-291-2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132009017&doi=10.5194%2fisprs-archives-XLIII-B2-2022-291-2022&partnerID=40&md5=e2af3f65cfaab7cd358e572e9c407b9a,"With the development and widespread application of aerial LiDAR, point cloud data can easily be acquired and used in many fields. The accurate detection of buildings from an aerial LiDAR point cloud has attracted much attention owing to its wide range of applications, such as updating building maps and constructing 3D city models. However, such applications remain challenging in the fields of photogrammetry, remote sensing, and computer vision. In this paper, we discuss the features that contribute to building detection accuracy from an aerial LiDAR point cloud using a deep-learning-based method (KPConv). We evaluated the influence of neighborhood size, intensity, RGB, and normal vectors on building detection. The study area was approximately 6 km2, consisting of 133 million points and 8,099 buildings. The density of the point cloud data was eight points/m2. We compared search radii of 4, 10, 25, and 50 m for finding neighboring points. The results suggest that an optimal neighborhood size improves the accuracy of building detection. For searching neighboring points, a radius of 25 m is optimal when the building area is less than 1000 m2, whereas a radius of 50 m is optimal when the building area is larger than 1000 m2.We also compared different features as inputs to KPConv for training and testing, such as i) 3D coordinates only, ii) 3D coordinates and intensity, iii) 3D coordinates and RGB, iv) 3D coordinates and normal vectors, and v) 3D coordinates, intensity, RGB, and normal vectors. The results suggest that neither intensity nor normal vectors contribute to the accuracy of building detection, while the features of RGB have a limited effect on the results.  © 2022. International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All rights reserved. ",Aerial LiDAR; Building detection; Deep Learning; Intensity; Neighborhood size; Normal vectors; Point cloud; RGB,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85132009017
Shao W.; Kakizaki K.; Araki S.; Mukai T.,"Shao, Wanpeng (57461744500); Kakizaki, Ken'ichi (36876160100); Araki, Shunsuke (7402410948); Mukai, Tomohisa (42661692100)",57461744500; 36876160100; 7402410948; 42661692100,Automated Two-Stage Approach for Damage Detection of Surface Defects in Historical Buildings,2022,"Proceedings - 2022 IEEE 46th Annual Computers, Software, and Applications Conference, COMPSAC 2022",,,,1816,1821,5,0,10.1109/COMPSAC54236.2022.00289,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136959344&doi=10.1109%2fCOMPSAC54236.2022.00289&partnerID=40&md5=cb9a29e8d2eb36dd8d6a14e710d2595e,"Damages of reinforced concrete buildings caused by aging or complicated environmental factors have become a worldwide problem. It is critical to accurately obtain damage information to determine the current state of the aging structure or its levels of decay. However, the inspection of multiple damages o the whole surface of a concrete structure is challenging. In this study, we present a two-stage method for damage detection of surface deflects of reinforced concrete buildings in point clouds captured by a terrestrial laser scanner using a 3D neural network and a novel cluster analysis technique. In the first stage, we divide the whole building into 3D grids, then a classification of multiple damages is performed using PointNet++ along with 3D data with color information mapped on it. In the second stage, we propose a four-step post-processing method based on cluster analysis including removal of isolated damaged clusters, dilation, and filling to develop the detection results. Experimental results show that the voxel-based recall rate reaches 0.928 and the precision rate reaches 0.753. The proposed method offers an acceptable damage detection performance on aging concrete surfaces. © 2022 IEEE.",aging; cluster analysis; PointNet++; reinforced concrete building; two-stage damage detection,Conference paper,Final,,Scopus,2-s2.0-85136959344
Hsieh C.-S.; Ruan X.-J.,"Hsieh, Chia-Sheng (14041609100); Ruan, Xiang-Jie (57211665749)",14041609100; 57211665749,Automated Semantic Segmentation of Indoor Point Clouds from Close-Range Images with Three-Dimensional Deep Learning,2023,Buildings,13,2,468,,,,1,10.3390/buildings13020468,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149237770&doi=10.3390%2fbuildings13020468&partnerID=40&md5=14502c284b46baad924b2f5eac13c7d4,"The creation of building information models requires acquiring real building conditions. The generation of a three-dimensional (3D) model from 3D point clouds involves classification, outline extraction, and boundary regularization for semantic segmentation. The number of 3D point clouds generated using close-range images is smaller and tends to be unevenly distributed, which is not conducive to automated modeling processing. In this paper, we propose an efficient solution for the semantic segmentation of indoor point clouds from close-range images. A 3D deep learning framework that achieves better results is further proposed. A dynamic graph convolutional neural network (DGCNN) 3D deep learning method is used in this study. This method was selected to learn point cloud semantic features. Moreover, more efficient operations can be designed to build a module for extracting point cloud features such that the problem of inadequate beam and column classification can be resolved. First, DGCNN is applied to learn and classify the indoor point cloud into five categories: columns, beams, walls, floors, and ceilings. Then, the proposed semantic segmentation and modeling method is utilized to obtain the geometric parameters of each object to be integrated into building information modeling software. The experimental results show that the overall accuracy rates of the three experimental sections of Area_1 in the Stanford 3D semantic dataset test results are 86.9%, 97.4%, and 92.5%. The segmentation accuracy of corridor 2F in a civil engineering building is 94.2%. In comparing the length with the actual on-site measurement, the root mean square error is found to be ±0.03 m. The proposed method is demonstrated to be capable of automatic semantic segmentation from 3D point clouds with indoor close-range images. © 2023 by the authors.",3D point cloud; building information model; deep learning; semantic segmentation,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85149237770
Verajagadheswa P.; Soundar Kandasamy P.; Elangovan K.; Rajesh Elara M.; Bui M.V.; Vu Le A.,"Verajagadheswa, Prabakaran (57432130400); Soundar Kandasamy, Prathap (57430726600); Elangovan, Karthikeyan (56979171300); Rajesh Elara, Mohan (36456051800); Bui, Minh V. (57430726700); Vu Le, Anh (57209297313)",57432130400; 57430726600; 56979171300; 36456051800; 57430726700; 57209297313,A novel autonomous staircase cleaning system with robust 3D-Deep Learning-based perception technique for Area-Coverage,2022,Expert Systems with Applications,194,,116528,,,,7,10.1016/j.eswa.2022.116528,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123714419&doi=10.1016%2fj.eswa.2022.116528&partnerID=40&md5=94701dad95f200010624257ac4506649,"Cleaning the staircases is the next big leap for every commercial cleaning robot in order to accomplish a full-fledged cleaning of a constructed buildings. Such an effort could be witnessed in the academic literature where a robotic system can autonomously clean the staircase by ascending. However, none of the existing staircase traversing platforms demonstrated the ability to perform both ascending and descending motion while cleaning, which can significantly improvise the overall robot's performance. In this paper, we propose a novel reconfigurable cleaning robotic platform called sTetro_plotter, which can perform both ascend and descend motion in the staircases. Pointedly, in this work, we presented a perception framework for the developed robot to traverse on the staircase and perform area coverage autonomously. The framework was constructed with a pointNet++ based feature extractor and classification and regression network to generate a bounding box on the targeted feature. Also, we discussed the process of a staircase descending through tracking the generated bounding box. We implemented a sweeping-based lidar device that can generate a 3D point cloud by sensing its environment. We evaluated the performance of the proposed robot and its perception system through conducting experiments in real-world scenarios. The experimental trials successfully demonstrate the ability of the sTetro_plotter robot to perform autonomous area coverage while traversing on the staircase using the developed perception framework. © 2022 Elsevier Ltd",3D Point Cloud; Area Coverage; Building Maintenance; Cleaning System; Perception for Autonomy; Staircase Traversing,Article,Final,,Scopus,2-s2.0-85123714419
Wang D.; Wang J.; Scaioni M.; Si Q.,"Wang, Duo (57207431247); Wang, Jin (57882088400); Scaioni, Marco (8261815100); Si, Qi (57213141618)",57207431247; 57882088400; 8261815100; 57213141618,Coarse-to-fine classification of road infrastructure elements from mobile point clouds using symmetric ensemble point network and euclidean cluster extraction,2020,Sensors (Switzerland),20,1,225,,,,6,10.3390/s20010225,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077610038&doi=10.3390%2fs20010225&partnerID=40&md5=9a180aa8e62511fc9b4ede3ed2dd383f,"Classifying point clouds obtained from mobile laser scanning of road environments is a fundamental yet challenging problem for road asset management and unmanned vehicle navigation. Deep learning networks need no prior knowledge to classify multiple objects, but often generate a certain amount of false predictions. However, traditional clustering methods often involve leveraging a priori knowledge, but may lack generalisability compared to deep learning networks. This paper presents a classification method that coarsely classifies multiple objects of road infrastructure with a symmetric ensemble point (SEP) network and then refines the results with a Euclidean cluster extraction (ECE) algorithm. The SEP network applies a symmetric function to capture relevant structural features at different scales and select optimal sub-samples using an ensemble method. The ECE subsequently adjusts points that have been predicted incorrectly by the first step. The experimental results indicate that this method effectively extracts six types of road infrastructure elements: road surfaces, buildings, walls, traffic signs, trees and streetlights. The overall accuracy of the SEP-ECE method improves by 3.97% with respect to PointNet. The achieved average classification accuracy is approximately 99.74%, which is suitable for practical use in transportation network management. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.",Deep learning; Euclidean cluster extraction; Mobile laser scanning; Point cloud; Road infrastructure; Symmetric ensemble point network,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85077610038
Yin C.; Wang B.; Gan V.J.L.; Wang M.; Cheng J.C.P.,"Yin, Chao (57221927168); Wang, Boyu (57221940953); Gan, Vincent J.L. (56282821800); Wang, Mingzhu (57202642024); Cheng, Jack C.P. (57204665849)",57221927168; 57221940953; 56282821800; 57202642024; 57204665849,Automated semantic segmentation of industrial point clouds using ResPointNet++,2021,Automation in Construction,130,,103874,,,,28,10.1016/j.autcon.2021.103874,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112036660&doi=10.1016%2fj.autcon.2021.103874&partnerID=40&md5=296f3f3b576a7015352804171a0de0e9,"Currently, as-built building information modeling (BIM) models from point clouds show great potential in managing building information. The automatic creation of as-built BIM models from point clouds is important yet challenging due to the inefficiency of semantic segmentation. To overcome this challenge, this paper proposes a novel deep learning-based approach, ResPointNet++, by integrating deep residual learning with conventional PointNet++ network. To unleash the power of deep learning methods, this study firstly builds an expert-labeled high-quality industrial LiDAR dataset containing 80 million data points collected from four different industrial scenes covering nearly 4000 m2. Our dataset consists of five typical semantic categories of plumbing and structural components (i.e., pipes, pumps, tanks, I-shape and rectangular beams). Second, we introduce two effective neural modules including local aggregation operator and residual bottleneck modules to learn complex local structures from neighborhood regions and build up deeper point cloud networks with residual settings. Based on these two neural modules, we construct our proposed network, ResPointNet++, with a U-Net style encoder-decoder structure. To validate the proposed method, comprehensive experiments are conducted to compare the robustness and efficiency of our ResPointNet++ with two representative baseline methods (PointNet and PointNet++) on our benchmark dataset. The experimental results demonstrate that ResPointNet++ outperforms two baselines with a remarkable overall segmentation accuracy of 94% and mIoU of 87%, which is 23% and 42% higher than that of conventional PointNet++, respectively. Finally, ablation studies are performed to evaluate the influence of design choices of the local aggregation operator module including input feature type and aggregation function type. This study contributes to automated 3D scene interpretation of industrial point clouds as well as the as-built BIM creation for industrial components such as pipes and beams. © 2021 Elsevier B.V.",As-built BIM; Deep learning; Industrial object recognition; Laser scanning; Local aggregation operator; Point clouds; PointNet++; Residual learning; Semantic segmentation,Article,Final,,Scopus,2-s2.0-85112036660
Xiu H.; Vinayaraj P.; Kim K.-S.; Nakamura R.; Yan W.,"Xiu, Haoyi (57215270239); Vinayaraj, Poliyapram (54380886600); Kim, Kyoung-Sook (57184508400); Nakamura, Ryosuke (55439424500); Yan, Wanglin (38362610300)",57215270239; 54380886600; 57184508400; 55439424500; 38362610300,3D semantic segmentation for high-resolution aerial survey derived point clouds using deep learning (demonstration),2018,GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems,,,,588,591,3,11,10.1145/3274895.3274950,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058658588&doi=10.1145%2f3274895.3274950&partnerID=40&md5=15c76a1f570fe79f3f2b40ce7e5eb938,"Three-dimensional (3D) Semantic segmentation of aerial derived point cloud aims at assigning each point to a semantic class such as building, tree, road, and so on. Accurate 3D-segmentation results can be used as an essential information for constructing 3D city models, for assessing the urban expansion and economical condition. However, the fine-grained semantic segmentation is a challenge in high-resolution point cloud due to irregularly distributed points unlike regular pixels of image. In this demonstration, we present a case study to apply PointNet, a novel deep learning network, to outdoor aerial survey derived point clouds by considering intensity (depth) as well as spectral information (RGB). PointNet was basically designed for indoor point cloud data based on the permutation invariance of 3D points. We firstly fuse two surveying datasets of Light Detection and ranging (LiDAR) and aerial images for generating multi-sourced aerial point clouds (RGB-DI). Then, each point of fused data is classified into a semantic class of ordinary building, public facility, apartment, factory, transportation network, park, and water by reworking PointNet. The result of our approach by using deep learning shows about 0.88 accuracy and 0.64 F-measure of semantic segmentation with the RGB-DI data we have fused. It outperforms a Support Vector Machine(SVM) approach based on geometric features of linearity, planarity, scattering, and verticality of a set of 3D points. © 2018 held by the owner/author(s).",3D-segmentation; Aerial images; Deep learning; Point cloud; PointNet,Conference paper,Final,,Scopus,2-s2.0-85058658588
Bayu A.; Wibisono A.; Wisesa H.A.; Intizhami N.S.; Jatmiko W.; Gamal A.,"Bayu, Azady (57211313745); Wibisono, Ari (55625531300); Wisesa, Hanif Arief (57189234078); Intizhami, Naili Suri (57211322215); Jatmiko, Wisnu (8568432600); Gamal, Ahmad (57200131887)",57211313745; 55625531300; 57189234078; 57211322215; 8568432600; 57200131887,Semantic Segmentation of Lidar Point Cloud in Rural Area,2019,"2019 IEEE International Conference on Communication, Networks and Satellite, Comnetsat 2019 - Proceedings",,,8844074,73,78,5,5,10.1109/COMNETSAT.2019.8844074,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073442780&doi=10.1109%2fCOMNETSAT.2019.8844074&partnerID=40&md5=bcd448d509e2faa11d1295340d9f39ff,"A 3D surface modeling format that is commonly used today is point cloud. 3D surface model segmentation could provide data for analysis in various fields. In the context of Geographic Information Systems, point cloud data obtained from the Light Detection and Ranging (LiDAR) sensor are used by machines to automatically identify objects such as houses, buildings, land, and rivers. There has been many Deep Learning approach through Convolutional Neural Network (CNN) that has been proven to be very capable for 2-dimensional imagery classification and segmentation. PointNet is a Deep Learning architecture that is designed so that the point cloud format that is still tabular form, can be directly convoluted by the CNN model. In this study, an improvement of PointNet is proposed for Point Cloud data of Kupang City. The Point Cloud data were acquired using an Unmanned Aerial Vehicle with a LiDAR sensor installed. The data were pre-processed and divided into training and testing data. The data were processed with the PointNet architecture and the model was tested using several metrics. The experiment shows that the PointNet architecture is capable on segmenting Geographical Point Cloud Data. In addition, incorporating voxel's color features could increase the performance of the segmentation. © 2019 IEEE.",Convolutional Neural Network; Deep Learning; LiDAR; Point Cloud; PointNet,Conference paper,Final,,Scopus,2-s2.0-85073442780
Xing X.; Qian Y.; Feng S.; Dong Y.; Matas J.,"Xing, Xiaoyan (57405684600); Qian, Yanlin (57194201188); Feng, Sibo (57353567800); Dong, Yuhan (8224043200); Matas, Jiri (7006443210)",57405684600; 57194201188; 57353567800; 8224043200; 7006443210,Point Cloud Color Constancy,2022,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,2022-June,,,19718,19727,9,0,10.1109/CVPR52688.2022.01913,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141777328&doi=10.1109%2fCVPR52688.2022.01913&partnerID=40&md5=8049d88a4687a2a7bea1f3da32a50586,"In this paper, we present Point Cloud Color Constancy, in short PCCC, an illumination chromaticity estimation algorithm exploiting a point cloud. We leverage the depth information captured by the time-of-flight (ToF) sensor mounted rigidly with the RGB sensor, and form a 6D cloud where each point contains the coordinates and RGB intensities, noted as (x,y,z, r,g, b). PCCC applies the PointNet architecture to the color constancy problem, deriving the illumination vector point-wise and then making a global decision about the global illumination chromaticity. On two popular RGB-D datasets, which we extend with illumination information, as well as on a novel benchmark, PCCC obtains lower error than the state-of-the-art algorithms. Our method is simple andfast, requiring merely 16 x 16-size input and reaching speed over 140 fps (CPU time), including the cost of building the point cloud and net inference. © 2022 IEEE.",Computational photography; Datasets and evaluation; Low-level vision,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85141777328
Chen X.; Jiang K.; Zhu Y.; Wang X.; Yun T.,"Chen, Xinxin (58379754600); Jiang, Kang (57208528587); Zhu, Yushi (57221845697); Wang, Xiangjun (55238016400); Yun, Ting (55273559900)",58379754600; 57208528587; 57221845697; 55238016400; 55273559900,Individual tree crown segmentation directly from uav-borne lidar data using the pointnet of deep learning,2021,Forests,12,2,131,1,22,21,62,10.3390/f12020131,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100411444&doi=10.3390%2ff12020131&partnerID=40&md5=b424decc7a73c89726d7a7581c8e76d6,"Accurate individual tree crown (ITC) segmentation from scanned point clouds is a fun-damental task in forest biomass monitoring and forest ecology management. Light detection and ranging (LiDAR) as a mainstream tool for forest survey is advancing the pattern of forest data acquisition. In this study, we performed a novel deep learning framework directly processing the forest point clouds belonging to the four forest types (i.e., the nursery base, the monastery garden, the mixed forest, and the defoliated forest) to realize the ITC segmentation. The specific steps of our approach were as follows: first, a voxelization strategy was conducted to subdivide the collected point clouds with various tree species from various forest types into many voxels. These voxels containing point clouds were taken as training samples for the PointNet deep learning framework to identify the tree crowns at the voxel scale. Second, based on the initial segmentation results, we used the height-related gradient information to accurately depict the boundaries of each tree crown. Meanwhile, the retrieved tree crown breadths of individual trees were compared with field measurements to verify the effectiveness of our approach. Among the four forest types, our results revealed the best performance for the nursery base (tree crown detection rate r = 0.90; crown breadth estimation R2 > 0.94 and root mean squared error (RMSE) < 0.2m). A sound performance was also achieved for the monastery garden and mixed forest, which had complex forest structures, complicated intersections of branches and different building types, with r = 0.85, R2 > 0.88 and RMSE < 0.6 m for the monastery garden and r = 0.80, R2 > 0.85 and RMSE < 0.8 m for the mixed forest. For the fourth forest plot type with the distribution of crown defoliation across the woodland, we achieved the performance with r = 0.82, R2 > 0.79 and RMSE < 0.7 m. Our method presents a robust framework inspired by the deep learning technology and computer graphics theory that solves the ITC segmentation problem and retrieves forest parameters under various forest conditions. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Airborne LiDAR data; Computer graphics; Deep learning; Individual tree crown segmentation,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85100411444
Morbidoni C.; Pierdicca R.; Paolanti M.; Quattrini R.; Mammoli R.,"Morbidoni, Christian (15136812700); Pierdicca, Roberto (56460209100); Paolanti, Marina (57188734162); Quattrini, Ramona (55755385800); Mammoli, Raissa (57202441160)",15136812700; 56460209100; 57188734162; 55755385800; 57202441160,Learning from synthetic point cloud data for historical buildings semantic segmentation,2020,Journal on Computing and Cultural Heritage,13,4,34,,,,28,10.1145/3409262,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092167437&doi=10.1145%2f3409262&partnerID=40&md5=26aa6f0385489c5289a9cb52d34566cf,"Historical heritage is demanding robust pipelines for obtaining Heritage Building Information Modeling models that are fully interoperable and rich in their informative content. The definition of efficient Scan-to-BIM workflows represent a very important step toward a more efficient management of the historical real estate, as creating structured three-dimensional (3D) models from point clouds is complex and time-consuming. In this scenario, semantic segmentation of 3D Point Clouds is gaining more and more attention, since it might help to automatically recognize historical architectural elements. The way paved by recent Deep Learning approaches proved to provide reliable and affordable degrees of automation in other contexts, as road scenes understanding. However, semantic segmentation is particularly challenging in historical and classical architecture, due to the shapes complexity and the limited repeatability of elements across different buildings, which makes it difficult to define common patterns within the same class of elements. Furthermore, as Deep Learning models requires a considerably large amount of annotated data to be trained and tuned to properly handle unseen scenes, the lack of (big) publicly available annotated point clouds in the historical building domain is a huge problem, which in fact blocks the research in this direction. However, creating a critical mass of annotated point clouds by manual annotation is very time-consuming and impractical. To tackle this issue, in this work we explore the idea of leveraging synthetic point cloud data to train Deep Learning models to perform semantic segmentation of point clouds obtained via Terrestrial Laser Scanning. The aim is to provide a first assessment of the use of synthetic data to drive Deep Learning–based semantic segmentation in the context of historical buildings. To achieve this purpose, we present an improved version of the Dynamic Graph CNN (DGCNN) named RadDGCNN. The main improvement consists on exploiting the radius distance. In our experiments, we evaluate the trained models on synthetic dataset (publicly available) about two different historical buildings: the Ducal Palace in Urbino, Italy, and Palazzo Ferretti in Ancona, Italy. RadDGCNN yields good results, demonstrating improved segmentation performances on the TLS real datasets. © 2020 Association for Computing Machinery.",Cultural heritage; Deep learning; Dynamic graph convolutional neural network; Historical building; Point cloud semantic segmentation; Radius distance; Scan-to-BIM; Synthetic point cloud,Article,Final,,Scopus,2-s2.0-85092167437
Matrone F.; Martini M.,"Matrone, Francesca (57195330111); Martini, Massimo (57209009649)",57195330111; 57209009649,TRANSFER LEARNING AND PERFORMANCE ENHANCEMENT TECHNIQUES FOR DEEP SEMANTIC SEGMENTATION OF BUILT HERITAGE POINT CLOUDS; [TRANSFERENCIA DE TÉCNICAS DE APRENDIZAJE Y MEJORA DEL RENDIMIENTO EN LA SEGMENTACIÓN SEMÁNTICA PROFUNDA DE NUBES DE PUNTOS DEL PATRIMONIO CONSTRUIDO],2021,Virtual Archaeology Review,12,25,,73,84,11,3,10.4995/var.2021.15318,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111484214&doi=10.4995%2fvar.2021.15318&partnerID=40&md5=74ee2cd13b9edac9443764fc80bc6008,"The growing availability of three-dimensional (3D) data, such as point clouds, coming from Light Detection and Ranging (LiDAR), Mobile Mapping Systems (MMSs) or Unmanned Aerial Vehicles (UAVs), provides the opportunity to rapidly generate 3D models to support the restoration, conservation, and safeguarding activities of cultural heritage (CH). The so-called scan-to-BIM process can, in fact, benefit from such data, and they can themselves be a source for further analyses or activities on the archaeological and built heritage. There are several ways to exploit this type of data, such as Historic Building Information Modelling (HBIM), mesh creation, rasterisation, classification, and semantic segmentation. The latter, referring to point clouds, is a trending topic not only in the CH domain but also in other fields like autonomous navigation, medicine or retail. Precisely in these sectors, the task of semantic segmentation has been mainly exploited and developed with artificial intelligence techniques. In particular, machine learning (ML) algorithms, and their deep learning (DL) subset, are increasingly applied and have established a solid state-of-the-art in the last half-decade. However, applications of DL techniques on heritage point clouds are still scarce; therefore, we propose to tackle this framework within the built heritage field. Starting from some previous tests with the Dynamic Graph Convolutional Neural Network (DGCNN), in this research close attention is paid to: i) the investigation of fine-tuned models, used as a transfer learning technique, ii) the combination of external classifiers, such as Random Forest (RF), with the artificial neural network, and iii) data augmentation results evaluation for the domain-specific ArCH dataset. Finally, after analysing the main advantages and critical aspects, a proposal is made evaluating the extent to which this methodology can also be useful for non-programming or domain experts. © 2021. All Rights Reserved.",aprendizaje profundo; cultural heritage; deep learning; deep neural networks; nubes de puntos; patrimonio cultural; point clouds; redes neuronales profundas; segmentación semántica; semantic segmentation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85111484214
Malinverni E.S.; Pierdicca R.; Paolanti M.; Martini M.; Morbidoni C.; Matrone F.; Lingua A.,"Malinverni, E.S. (14066631000); Pierdicca, R. (56460209100); Paolanti, M. (57188734162); Martini, M. (57209009649); Morbidoni, C. (15136812700); Matrone, F. (57195330111); Lingua, A. (6507402873)",14066631000; 56460209100; 57188734162; 57209009649; 15136812700; 57195330111; 6507402873,DEEP LEARNING for SEMANTIC SEGMENTATION of 3D POINT CLOUD,2019,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",42,2/W15,,735,742,7,42,10.5194/isprs-archives-XLII-2-W15-735-2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072167750&doi=10.5194%2fisprs-archives-XLII-2-W15-735-2019&partnerID=40&md5=4451f7ae78332a88f1344a7dc4863375,"Cultural Heritage is a testimony of past human activity, and, as such, its objects exhibit great variety in their nature, size and complexity; from small artefacts and museum items to cultural landscapes, from historical building and ancient monuments to city centers and archaeological sites. Cultural Heritage around the globe suffers from wars, natural disasters and human negligence. The importance of digital documentation is well recognized and there is an increasing pressure to document our heritage both nationally and internationally. For this reason, the three-dimensional scanning and modeling of sites and artifacts of cultural heritage have remarkably increased in recent years. The semantic segmentation of point clouds is an essential step of the entire pipeline; in fact, it allows to decompose complex architectures in single elements, which are then enriched with meaningful information within Building Information Modelling software. Notwithstanding, this step is very time consuming and completely entrusted on the manual work of domain experts, far from being automatized. This work describes a method to label and cluster automatically a point cloud based on a supervised Deep Learning approach, using a state-of-the-art Neural Network called PointNet++. Despite other methods are known, we have choose PointNet++ as it reached significant results for classifying and segmenting 3D point clouds. PointNet++ has been tested and improved, by training the network with annotated point clouds coming from a real survey and to evaluate how performance changes according to the input training data. It can result of great interest for the research community dealing with the point cloud semantic segmentation, since it makes public a labelled dataset of CH elements for further tests. © 2019 International Society for Photogrammetry and Remote Sensing. All rights reserved.",Classification; Deep Learning; Point Cloud; Segmentation; Synthetic Dataset,Conference paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85072167750
Ma Z.; Oude Elberink S.; Lin Y.; Xu P.; Xiang B.; Koch B.; Weinacker H.,"Ma, Zhenyu (57201976408); Oude Elberink, Sander (57792194200); Lin, Yaping (57202450197); Xu, Panpan (57218565532); Xiang, Binbin (57193681526); Koch, Barbara (15069557700); Weinacker, Holger (24466119600)",57201976408; 57792194200; 57202450197; 57218565532; 57193681526; 15069557700; 24466119600,Strict rule-based automatic training data extraction using Mobile laser scanning in urban area,2023,ISPRS Journal of Photogrammetry and Remote Sensing,195,,,313,334,21,0,10.1016/j.isprsjprs.2022.10.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144823561&doi=10.1016%2fj.isprsjprs.2022.10.007&partnerID=40&md5=bb06e2c98a943e129a0dcff620b1ea67,"To reduce the cost of manually annotating training data for supervised classifiers, we propose an automated approach to extract training data of urban objects in six classes: buildings, fences, man-made poles, vegetation, vehicles, and low objects. In this study, two segmentation algorithms are firstly implemented to generate meaningful objects from the non-ground point cloud. Then, we generated valid strict rules to label partial RANSAC (Random Sample Consensus) planes and meaningful objects as training data. The strict rules are built upon the semantic knowledge formed by the features of geometric, eigenvalue, RANSAC plane, multidimensional slice, and relative location. The accuracy of strict rule-based (SRB) training data is higher than 98.5 % for buildings, man-made poles, vegetation, and vehicles. The accuracy of low objects and fences reaches 97.10 % and 94.99 %, respectively. Finally, we compared the performance of the KPConv and PointNET++ networks trained by SRB and manually labeled training data to evaluate the effectiveness of our training data. The KPConv overall accuracy using manually labeled and (SRB) training data are 91.5 % and 86.8 % in the Paris dataset, 95.6 % and 92.0 % in the Freiburg dataset, respectively. The experiments demonstrate that automatically labeled training data can achieve similar accuracy compared to manual labels when coupled with two deep learning networks. Therefore, SRB training data extraction can effectively deal with the problem of training data scarcity and provide significant advancements in urban point cloud classification, where manual labeling of training data remains a crucial challenge. © 2022 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Deep learning; Meaningful object; Mobile laser scanning; Strict rule-based (SRB); Training data; Urban area,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85144823561
Haznedar B.; Bayraktar R.; Ozturk A.E.; Arayici Y.,"Haznedar, Bulent (57201991740); Bayraktar, Rabia (58042060600); Ozturk, Ali Emre (57225345078); Arayici, Yusuf (8328617900)",57201991740; 58042060600; 57225345078; 8328617900,Implementing PointNet for point cloud segmentation in the heritage context,2023,Heritage Science,11,1,2,,,,2,10.1186/s40494-022-00844-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145604582&doi=10.1186%2fs40494-022-00844-w&partnerID=40&md5=d7887d1b1011ca4629955b0a34193f9d,"Automated Heritage Building Information Modelling (HBIM) from the point cloud data has been researched in the last decade as HBIM can be the integrated data model to bring together diverse sources of complex cultural content relating to heritage buildings. However, HBIM modelling from the scan data of heritage buildings is mainly manual and image processing techniques are insufficient for the segmentation of point cloud data to speed up and enhance the current workflow for HBIM modelling. Artificial Intelligence (AI) based deep learning methods such as PointNet are introduced in the literature for point cloud segmentation. Yet, their use is mainly for manufactured and clear geometric shapes and components. To what extent PointNet based segmentation is applicable for heritage buildings and how PointNet can be used for point cloud segmentation with the best possible accuracy (ACC) are tested and analysed in this paper. In this study, classification and segmentation processes are performed on the 3D point cloud data of heritage buildings in Gaziantep, Turkey. Accordingly, it proposes a novel approach of activity workflow for point cloud segmentation with deep learning using PointNet for the heritage buildings. Twenty-eight case study heritage buildings are used, and AI training is performed using five feature labelling for segmentation namely, walls, roofs, floors, doors, and windows for each of these 28 heritage buildings. The dataset is divided into clusters with 80% training dataset and 20% prediction test dataset. PointNet algorithm was unable to provide sufficient accuracy in segmenting the point clouds due to deformation and deterioration on the existing conditions of the heritage case study buildings. However, if PointNet algorithm is trained with the restitution-based heritage data, which is called synthetic data in the research, PointNet algorithm provides high accuracy. Thus, the proposed approach can build the baseline for the accurate classification and segmentation of the heritage buildings. © 2023, The Author(s).",3D point cloud; Artificial intelligence; Cultural heritage; Deep learning; Segmentation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85145604582
Janssens-Coron E.; Guilbert E.,"Janssens-Coron, E. (39761681900); Guilbert, E. (55613228714)",39761681900; 55613228714,Ground point filtering from airborne lidar point clouds using deep learning: A preliminary study,2019,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",42,2/W13,,1559,1565,6,12,10.5194/isprs-archives-XLII-2-W13-1559-2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067496635&doi=10.5194%2fisprs-archives-XLII-2-W13-1559-2019&partnerID=40&md5=ff26e5f65f8103733f1b0665be838524,"Airborne lidar data is commonly used to generate point clouds over large areas. These points can be classified into different categories such as ground, building, vegetation, etc. The first step for this is to separate ground points from non-ground points. Existing methods rely mainly on TIN densification but there performance varies with the type of terrain and relies on the user's experience who adjusts parameters accordingly. An alternative may be on the use of a deep learning approach that would limit user's intervention. Hence, in this paper, we assess a deep learning architecture, PointNet, that applies directly to point clouds. Our preliminary results show mitigating classification rates and further investigation is required to properly train the system and improve the robustness, showing issues with the choices we made in the preprocessing. Nonetheless, our analysis suggests that it is necessary to enrich the architecture of the network to integrate the notion of neighbourhood at different scales in order to increase the accuracy and the robustness of the treatment as well as its capacity to treat data from different geographical contexts. © Authors 2019.",classification; deep learning; ground point; lidar,Conference paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85067496635
Tian B.; Loonen R.C.G.M.; Hensen J.L.M.,"Tian, B. (57900310200); Loonen, R.C.G.M. (55504415000); Hensen, J.L.M. (7006934537)",57900310200; 55504415000; 7006934537,Combining point cloud and surface methods for modeling partial shading impacts of trees on urban solar irradiance,2023,Energy and Buildings,298,,113420,,,,0,10.1016/j.enbuild.2023.113420,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170405680&doi=10.1016%2fj.enbuild.2023.113420&partnerID=40&md5=7b5ffd3a0e0ba20c32031e0b713748d7,"Although trees and urban vegetation have a significant influence on solar irradiation in the built environment, their impact on daylight and energy consumption is often not considered in building performance and urban environment simulation studies. This paper presents a novel method for comprehensive solar irradiance assessment that considers the dynamic partial shading impacts from trees. The proposed method takes urban point clouds as input and consists of three subsequent steps: (a) DGCNN-based segmentation, (b) fusion model generation, (c) matrix-based irradiance calculation. The method is validated by comparing model outputs with field measurement data, and an inter-model comparison with eleven state-of-the-art tree shading modeling approaches. Analyses carried out on daily and long-term basis show that the proposed fusion model can significantly reduce simulation errors compared to alternative approaches, while limiting the required input data to a minimum. The primary source of uncertainty stems from mismatches between tree morphology in the fusion model and reality, attributable to phenological growth and seasonal variations. © 2023 The Author(s)",Dynamic graph CNN; Fusion model; Solar irradiance; Tree shading,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85170405680
Liu R.; Ren L.; Wang F.,"Liu, Renpeng (57377746900); Ren, Lisheng (57672583700); Wang, Fang (57199195670)",57377746900; 57672583700; 57199195670,3D point cloud of single tree branches and leaves semantic segmentation based on modified pointnet network,2021,Journal of Physics: Conference Series,2074,1,12026,,,,3,10.1088/1742-6596/2074/1/012026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121457959&doi=10.1088%2f1742-6596%2f2074%2f1%2f012026&partnerID=40&md5=74c91e860bc07e5fd58d4664a3d455b2,"Semantic segmentation of single tree 3D point cloud is one of the key technologies in building tree model. It plays an important role in tree skeleton extraction, tree pruning, tree model reconstruction and other fields. Because the area of a single leaf is smaller than that of the whole tree, the segmentation of branches and leaves is a challenging problem. In view of the above problems, this paper first migrates PointNet to the tree branch and leaf point cloud segmentation, and proposes an automatic segmentation method based on improved PointNet. According to the difference of normal direction between leaves and branches, the point cloud information of three dimensions coordinates, color and normal vector is input into the point feature space. In data processing, increase the number of each block data, so that the network can better learn features. MLP is added to the original PointNet network to improve the ability of extracting and learning local features. In addition, in the process of feature extraction, jump connection is added to realize feature reuse and make full use of different levels of features. The original 1×1 filter of PointNet is replaced by 3×1 filter to improve the segmentation accuracy of tree point cloud. The focus loss function focal loss is introduced into the field of 3D point cloud to reduce the impact of the imbalance of point cloud samples on the results. The results show that the improved method improves the accuracy of tree branch point cloud segmentation compared with the original PointNet for branch and leaf segmentation. The segmentation accuracy of structural elements of branches and leaves is more than 88%, and MIoU is 48%. © 2021 Institute of Physics Publishing. All rights reserved.",Deep Learning; Leaves; Point Cloud; Point Cloud Segmentation; PointNet; Semantic Segmentation; Tree Branches,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85121457959
Chen D.; Ma X.; Lu X.; Xiao J.,"Chen, D. (56376005300); Ma, X. (57742390000); Lu, X. (57742974200); Xiao, J. (57742675300)",56376005300; 57742390000; 57742974200; 57742675300,APPLICATION OF A SHELLNET BASED APPROACH TO SEMANTIC SEGMENTATION IN URBAN POINT CLOUD,2022,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",43,B2-2022,,169,175,6,0,10.5194/isprs-archives-XLIII-B2-2022-169-2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132023489&doi=10.5194%2fisprs-archives-XLIII-B2-2022-169-2022&partnerID=40&md5=be5caf3207e99e945f4880ca74663b20,"In recent years, the popularity of airborne, vehicle-borne, and terrestrial 3D laser scanners has driven the rapid development of 3D point cloud processing methods. The 3D laser scanning technology has the characteristics of non-contact, high density, high accuracy, and digitalization, which can achieve comprehensive and fast 3D scanning of urban point clouds. To address the current situation that it is difficult to accurately segment urban point clouds in complex scenes from 3D laser scanned point clouds, a technical process for accurate and fast semantic segmentation of urban point clouds is proposed. In this study, the point clouds are first denoised, then the samples are annotated and sample sets are created based on the point cloud features of the category targets using CloudCompare software, followed by an end-to-end trainable optimization network-ShellNet, to train the urban point cloud samples, and finally, the models are evaluated on a test set. The method achieved IoU metrics of 89.83% and 73.74% for semantic segmentation of buildings and rods-like objects respectively. From the visualization results of the test set, the algorithm is feasible and robust, providing a new idea and method for semantic segmentation of large-scale urban scenes.  © 2022. International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All rights reserved. ",3D objects detection; Mobile laser scanning; Point cloud; Semantic segmentation; ShellNet; Urban,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85132023489
Soilán M.; Tardy H.; González-Aguilera D.,"Soilán, M. (56803886700); Tardy, H. (57742386000); González-Aguilera, D. (24477009700)",56803886700; 57742386000; 24477009700,DEEP LEARNING-BASED ROAD SEGMENTATION OF 3D POINT CLOUDS FOR ASSISTING ROAD ALIGNMENT PARAMETERIZATION,2022,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",43,B2-2022,,283,290,7,1,10.5194/isprs-archives-XLIII-B2-2022-283-2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132005710&doi=10.5194%2fisprs-archives-XLIII-B2-2022-283-2022&partnerID=40&md5=b5b34223a58e7d802b2f4e0fe6125ec7,"The need for transportation infrastructure digitalization is becoming more important, and efficient data collection and processing workflows have to be established and pose a great research challenge. This paper presents a fully automated method for the geometric parametrization of the road alignment from 3D point clouds acquired with a low-cost mobile mapping system. It exploits the Point Transformer Deep Learning architecture in order to segment the 3D point cloud in four different classes, which include road markings. Those markings are then used as a reference to extract the alignment trajectory path, classify its geometries (straight lines, circular arcs, and clothoids) and then parametrize it, extracting data to easily generate alignment data that may follow the standard schema of the Industry Foundation Classes (IFC). Both the deep learning architecture and the geometry parametrization process show promising results to develop automatic workflows that extract precise as-built data of the infrastructure from 3D point clouds.  © 2022. International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All rights reserved. ",3D point cloud processing; BIM; Deep Learning; Mobile Mapping System; Point Transformer; Road alignment,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85132005710
Koo B.; Jung R.; Yu Y.,"Koo, Bonsang (7101738312); Jung, Raekyu (57219890755); Yu, Youngsu (57204916978)",7101738312; 57219890755; 57204916978,Automatic classification of wall and door BIM element subtypes using 3D geometric deep neural networks,2021,Advanced Engineering Informatics,47,,101200,,,,32,10.1016/j.aei.2020.101200,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095915865&doi=10.1016%2fj.aei.2020.101200&partnerID=40&md5=7ae07d46c416126392153515385912d9,"With the growing adoption of Building Information Modeling (BIM), specialized applications have been developed to perform domain-specific analyses. These applications need tailored information with respect to a BIM model element's attributes and relationships. In particular, architectural elements need further qualification concerning their geometric and functional ‘subtypes’ to support exact simulations and compliance checks. BIM and its underlying data schema, the Industry Foundation Classes (IFC), provide a rich representation with which to exchange semantic entity and relationship data. However, subtypes for individual elements are not represented by default and often require manual designation, leaving it vulnerable to errors and omissions. Existing research to enrich the semantics of IFC model entities employed domain-specific rule sets that scrutinize their legitimacy and modify them, if and when necessary. However, such an approach is limited in their scalability and comprehensibility. This study explored the use of 3D geometric deep neural networks originating from computer vision research. Specifically, Multi-view CNN(MVCNN) and PointNet were investigated to determine their applicability in extracting unique features of door (IfcDoor) and wall (IfcWall) element subtypes, and in turn be leveraged to automate subtype classifications. Test results indicated MVCNN as having the best prediction performance, while PointNet's accuracy was hampered by resolution loss due to selective use of point cloud data. The research confirmed deep neural networks as a viable solution to distinguishing BIM element subtypes, the critical factor being their ability to detect subtle differences in local geometries. © 2020",Building information modeling; Deep learning; Industry foundation classes; Machine learning; Semantic integrity,Article,Final,,Scopus,2-s2.0-85095915865
González-Collazo S.M.; Balado J.; Garrido I.; Grandío J.; Rashdi R.; Tsiranidou E.; del Río-Barral P.; Rúa E.; Puente I.; Lorenzo H.,"González-Collazo, Silvia María (57446439400); Balado, Jesús (57195102154); Garrido, Iván (57196025483); Grandío, Javier (57219132675); Rashdi, Rabia (57580991900); Tsiranidou, Elisavet (57911573100); del Río-Barral, Pablo (57214223328); Rúa, Erik (57226303239); Puente, Iván (55258413100); Lorenzo, Henrique (6603882725)",57446439400; 57195102154; 57196025483; 57219132675; 57580991900; 57911573100; 57214223328; 57226303239; 55258413100; 6603882725,Santiago urban dataset SUD: Combination of Handheld and Mobile Laser Scanning point clouds,2024,Expert Systems with Applications,238,,121842,,,,0,10.1016/j.eswa.2023.121842,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173267884&doi=10.1016%2fj.eswa.2023.121842&partnerID=40&md5=2c9ac7d47ee831cfee4c5a11468664a3,"Santiago Urban Dataset SUD is a real dataset that combines Mobile Laser Scanning (MLS) and Handheld Mobile Laser Scanning (HMLS) point clouds. The data is composed by 2 km of streets, sited in Santiago de Compostela (Spain). Point clouds undergo a manual labelling process supported by both heuristic and Deep Learning methods, resulting in the classification of eight specific classes: road, sidewalk, curb, buildings, vehicles, vegetation, poles, and others. Three PointNet++ models were trained; the first one using MLS point clouds, the second one with HMLS point clouds and the third one with both H&MLS point clouds. In order to ascertain the quality and efficacy of each Deep Learning model, various metrics were employed, including confusion matrices, precision, recall, F1-score, and IoU. The results are consistent with other state-of-the-art works and indicate that SUD is valid for comparing point cloud semantic segmentation works. Furthermore, the survey's extensive coverage and the limited occlusions indicate the potential utility of SUD in urban mobility research. © 2023 The Author(s)",Deep learning; LiDAR; Mobile mapping systems; Occlusions; Semantic segmentation; Urban mobility,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85173267884
Li J.; Chen B.M.; Lee G.H.,"Li, Jiaxin (58577876400); Chen, Ben M. (7408611448); Lee, Gim Hee (37013313400)",58577876400; 7408611448; 37013313400,SO-Net: Self-Organizing Network for Point Cloud Analysis,2018,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,8579077,9397,9406,9,703,10.1109/CVPR.2018.00979,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052978187&doi=10.1109%2fCVPR.2018.00979&partnerID=40&md5=e5e869f1c807e52b8968d2c5e014fcfd,"This paper presents SO-Net, a permutation invariant architecture for deep learning with orderless point clouds. The SO-Net models the spatial distribution of point cloud by building a Self-Organizing Map (SOM). Based on the SOM, SO-Net performs hierarchical feature extraction on individual points and SOM nodes, and ultimately represents the input point cloud by a single feature vector. The receptive field of the network can be systematically adjusted by conducting point-to-node k nearest neighbor search. In recognition tasks such as point cloud reconstruction, classification, object part segmentation and shape retrieval, our proposed network demonstrates performance that is similar with or better than state-of-the-art approaches. In addition, the training speed is significantly faster than existing point cloud recognition networks because of the parallelizability and simplicity of the proposed architecture. Our code is available at the project website.1 © 2018 IEEE.",,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85052978187
Li Z.; Zhang W.; Shan J.,"Li, Z. (57211530508); Zhang, W. (57196272204); Shan, J. (57219263367)",57211530508; 57196272204; 57219263367,HOLISTIC PARAMETRIC RECONSTRUCTION of BUILDING MODELS from POINT CLOUDS,2020,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",43,B2,,689,695,6,5,10.5194/isprs-archives-XLIII-B2-2020-689-2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091109448&doi=10.5194%2fisprs-archives-XLIII-B2-2020-689-2020&partnerID=40&md5=b5b165fdf7b15f0e0bea39f7368a59a5,"Building models are conventionally reconstructed by building roof points via planar segmentation and then using a topology graph to group the planes together. Roof edges and vertices are then mathematically represented by intersecting segmented planes. Technically, such solution is based on sequential local fitting, i.e., the entire data of one building are not simultaneously participating in determining the building model. As a consequence, the solution is lack of topological integrity and geometric rigor. Fundamentally different from this traditional approach, we propose a holistic parametric reconstruction method which means taking into consideration the entire point clouds of one building simultaneously. In our work, building models are reconstructed from predefined parametric (roof) primitives. We first use a well-designed deep neural network to segment and identify primitives in the given building point clouds. A holistic optimization strategy is then introduced to simultaneously determine the parameters of a segmented primitive. In the last step, the optimal parameters are used to generate a watertight building model in CityGML format. The airborne LiDAR dataset RoofN3D with predefined roof types is used for our test. It is shown that PointNet++ applied to the entire dataset can achieve an accuracy of 83% for primitive classification. For a subset of 910 buildings in RoofN3D, the holistic approach is then used to determine the parameters of primitives and reconstruct the buildings. The achieved overall quality of reconstruction is 0.08 meters for point-surface-distance or 0.7 times RMSE of the input LiDAR points. This study demonstrates the efficiency and capability of the proposed approach and its potential to handle large scale urban point clouds. © 2020 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives.",Building Modelling; CityGML; Deep Neural Network; Point Cloud; Primitives; Semantic Segmentation,Conference paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85091109448
Shao W.; Kakizaki K.; Araki S.; Mukai T.,"Shao, Wanpeng (57461744500); Kakizaki, Ken'ichi (36876160100); Araki, Shunsuke (7402410948); Mukai, Tomohisa (42661692100)",57461744500; 36876160100; 7402410948; 42661692100,Damage Detection of the RC Building in TLS Point Clouds Using 3D Deep Neural Network,2023,Seimitsu Kogaku Kaishi/Journal of the Japan Society for Precision Engineering,89,1,,70,76,6,0,10.2493/jjspe.89.70,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146073958&doi=10.2493%2fjjspe.89.70&partnerID=40&md5=5bda940e5384cbdcfe078fe62aefb850,"Nowadays, it is possible to capture the whole surface areas of buildings in three-dimensional point clouds using laser scanners. However, it is still challenging to find the damaged areas of the building data automatically. The objective of the study is to investigate the use of deep neural networks in combination with the building data captured by the terrestrial laser scanner for damage detection. The post-seismic building data for our experiments is from a structural lab. To find out what kinds of DNNs are useful for damage detection, the deep neural networks we choose are PointNet and PointNet++ (MSG, MRG, and SSG). Since innovative DNNs can only directly operate on small 3D rigid models, we transform the detection problem into a classification problem by voxelizing the whole façade before feeding into the 3D DNNs. Meanwhile, we find a pair of optimal parameters after investigating the impact of different point sizes and voxel sizes on detection results. By comparison, we perform a point-based classification by Random Forest to highlight the effectiveness of our approach. © 2023 Japan Society for Precision Engineering. All rights reserved.",damage detection; deep neural networks; earthquake; point clouds; reinforced concrete building,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85146073958
Hamid N.; Wibisono A.; Anwar Ma'Sum M.; Gamal A.; Ardhianto R.; Arymurthy A.M.; Jatmiko W.,"Hamid, Nur (52663351300); Wibisono, Ari (55625531300); Anwar Ma'Sum, M. (57213817389); Gamal, Ahmad (57200131887); Ardhianto, Roni (57200085262); Arymurthy, Aniati Murni (36815724000); Jatmiko, Wisnu (8568432600)",52663351300; 55625531300; 57213817389; 57200131887; 57200085262; 36815724000; 8568432600,3D Edge Convolution in Deep Neural Network Implementation for Land Cover Semantic Segmentation of Airborne LiDAR Data,2019,"2019 4th Asia-Pacific Conference on Intelligent Robot Systems, ACIRS 2019",,,8935980,216,220,4,1,10.1109/ACIRS.2019.8935980,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078064012&doi=10.1109%2fACIRS.2019.8935980&partnerID=40&md5=5fc7b5538adcf1089d57d7388b5d09df,"3-dimensional data contains more informative visualization than a 2-dimensional one. LiDAR sensor produces 3D data or point cloud data. There have been many implementations of LiDAR data such as for building detection, urban area modeling, and land cover analysis. This study will analyze land cover because of its substantial benefits. The purpose of this study is to produce semantic segmentation of land cover from LiDAR data by implementing EdgeConv Algorithm from Dynamic Graph Convolutional Neural Network (DGCNN). The dataset in this study is LiDAR data of Kupang, one of the areas in Indonesia. This work achieves the average accuracy of 67.76% for DGCNN better than the state-of-the-art method PointNet (previous method) with 64.97% by implementing the point cloud dataset from LiDAR data of Kupang. This is because the edge convolution could recognize the global shape structure and local neighborhood information so that it could improve the segmentation performance result. © 2019 IEEE.",3-dimensional edge detection; 3D CNN; edge convolution; land cover; lidar; semantic segmentation,Conference paper,Final,,Scopus,2-s2.0-85078064012
,,,,,,,,,,,,,,,,,,,,,
CATEGORY 3.2,,,,,,,,,,,,,,,,,,,,,
Scopus search query:,,,"TITLE-ABS-KEY ( ( ( ""Spherical projection"" OR ""voxel grid projection"" ) AND ( ""3D data"" OR ""pointcloud"" OR ""point cloud"" ) AND ( ""construction industry"" OR ""building"" OR ""AEC"" OR ""BIM"" ) ) ) AND PUBYEAR > 2007 AND PUBYEAR < 2025 AND ( LIMIT-TO ( DOCTYPE,""ar"" ) OR LIMIT-TO ( DOCTYPE,""cp"" ) )  AND ( LIMIT-TO ( LANGUAGE,""English"" ) ) ",,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,
Xiao A.; Yang X.; Lu S.; Guan D.; Huang J.,"Xiao, Aoran (57219688834); Yang, Xiaofei (57191641844); Lu, Shijian (8439329200); Guan, Dayan (57202644096); Huang, Jiaxing (57219508311)",57219688834; 57191641844; 8439329200; 57202644096; 57219508311,FPS-Net: A convolutional fusion network for large-scale LiDAR point cloud segmentation,2021,ISPRS Journal of Photogrammetry and Remote Sensing,176,,,237,249,12,27,10.1016/j.isprsjprs.2021.04.011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105590610&doi=10.1016%2fj.isprsjprs.2021.04.011&partnerID=40&md5=a111ea87ff4070702f6f093b4fa8361d,"Scene understanding based on LiDAR point cloud is an essential task for autonomous cars to drive safely, which often employs spherical projection to map 3D point cloud into multi-channel 2D images for semantic segmentation. Most existing methods simply stack different point attributes/modalities (e.g. coordinates, intensity, depth, etc.) as image channels to increase information capacity, but ignore distinct characteristics of point attributes in different image channels. We design FPS-Net, a convolutional fusion network that exploits the uniqueness and discrepancy among the projected image channels for optimal point cloud segmentation. FPS-Net adopts an encoder-decoder structure. Instead of simply stacking multiple channel images as a single input, we group them into different modalities to first learn modality-specific features separately and then map the learnt features into a common high-dimensional feature space for pixel-level fusion and learning. Specifically, we design a residual dense block with multiple receptive fields as a building block in encoder which preserves detailed information in each modality and learns hierarchical modality-specific and fused features effectively. In the FPS-Net decoder, we use a recurrent convolution block likewise to hierarchically decode fused features into output space for pixel-level classification. Extensive experiments conducted on two widely adopted point cloud datasets show that FPS-Net achieves superior semantic segmentation as compared with state-of-the-art projection-based methods. Specifically, FPS-Net outperforms the state-of-the-art in both accuracy (4.9% higher than RangeNet++ and 2.8% higher than PolarNet in mIoU) and computation speed (15.0 FPS faster than SqueezeSegV3) for SemanticKITTI benchmark. For KITTI benchmark, FPS-Net achieves significant accuracy improvement (12.6% higher than RangeNet++ in mIoU) with comparable computation speed. In addition, the proposed modality fusion idea is compatible with typical projection-based methods and can be incorporated into them with consistent performance improvement. © 2021 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Autonomous driving; LiDAR; Point cloud; Scene understanding; Semantic segmentation; Spherical projection,Article,Final,,Scopus,2-s2.0-85105590610
Klokov A.A.; Pak D.U.; Khorin A.; Yudin D.A.; Kochiev L.; Luchinskiy V.D.; Bezuglyj V.D.,"Klokov, Alexey A. (57220752789); Pak, Di Un (58507798400); Khorin, Aleksandr (57219448658); Yudin, Dmitry A. (57223946179); Kochiev, Leon (57374424400); Luchinskiy, Vladimir D. (58506690900); Bezuglyj, Vitaly D. (58026004300)",57220752789; 58507798400; 57219448658; 57223946179; 57374424400; 58506690900; 58026004300,DAPS3D: Domain Adaptive Projective Segmentation of 3D LiDAR Point Clouds,2023,IEEE Access,11,,,79341,79356,15,0,10.1109/ACCESS.2023.3298706,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165868804&doi=10.1109%2fACCESS.2023.3298706&partnerID=40&md5=0df45d88438797358d91fcdea6afa59b,"LiDARs are one of the key sources of reliable environmental ranging information for autonomous vehicles. However, segmentation of 3D scene elements (roads, buildings, people, cars, etc.) based on LiDAR point clouds has limitations. On the one hand, point- and voxel-based segmentation neural networks do not offer sufficiently high speed. On the other hand, modern labeled datasets primarily consist of street scenes recorded for driverless cars and contain little data for mobile delivery robots or cleaners that must work in parks and yards with heavy pedestrian traffic. This article aims to overcome these limitations. We have proposed a novel approach called DAPS3D to train deep neural networks for 3D semantic segmentation. This approach is based on a spherical projection of a point cloud and LiDAR-specific masks, enabling the model to adapt to different types of LiDAR. First of all, we have introduced various high-speed multi-scale spherical projection segmentation models, including convolutional, recurrent, and transformer architectures. Among them, the SalsaNextRecLSTM architecture with recurrent blocks showed the best results. In particular, this model achieved the 83.5% mIoU metric for the SemanticKitti dataset with joint categories. Secondly, we have proposed several original augmentations for spherical projections of LiDAR data, including FoV, flip, and rotation augmentation, as well as a special T-Zone cutout. These augmentations increase the model's invariance when dealing with changes in the data domain. Finally, we introduce a new method to generate synthetic datasets for domain adaptation problems. We have developed two new datasets for validating 3D scene outdoor segmentation algorithms: the DAPS-1 dataset, which is based on the augmentation of the reconstructed 3D semantic map, and the DAPS-2 LiDAR dataset, collected by the on-board sensors of a cleaning robot in a park area. Particular attention is given to the performance of the developed models, demonstrating their ability to function in real-time. The code and datasets used in this study are publicly available at: github.com/subake/DAPS3D.  © 2013 IEEE.",artificial neural networks; Autonomous vehicles; computer vision; image segmentation; projection algorithm,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85165868804
Wang Z.; Xiong H.,"Wang, Zhihong (36651664900); Xiong, Hao (58373340400)",36651664900; 58373340400,Analysis of the Application of Deep Learning in Model Reconstruction of Ancient Buildings,2022,Advances in Multimedia,2022,,4273937,,,,0,10.1155/2022/4273937,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140823725&doi=10.1155%2f2022%2f4273937&partnerID=40&md5=bb6d522d0d662066b79d26820d9b367f,"With the rapid development of interactive 3D graphics technology, as well as the growing demand for virtual reality, digital urbanization and digital cultural heritage protection and time-consuming and inefficient traditional artificial building modeling methods have been far from meeting the rapid and intelligent needs of the application market and automatic. Architectural modeling methods have been paid more and more attention. Architectural modeling is an application-oriented comprehensive research field. According to different application scenarios, its research methods cover many technical fields and disciplines. This paper introduces a method of modeling ancient buildings using depth image estimation, spherical projection mapping, 3D adversarial generation network, and other techniques. The characteristics of architectural modeling methods are discussed from different disciplinary and technical perspectives. Second, the three major schools of architectural modeling technology, mainly the process modeling method, image modeling method, and point cloud modeling method, as well as the inverse process modeling method, which has attracted much attention and challenges in recent years, are summarized in detail. Then, the problem of building modeling is discussed. The problems and challenges of building modeling technology are analyzed, and the future development trend is predicted.  © 2022 Zhihong Wang and Hao Xiong.",,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85140823725
,,,,,,,,,,,,,,,,,,,,,
CATEGORY 3.3,,,,,,,,,,,,,,,,,,,,,
Scopus search query:,,,"TITLE-ABS-KEY ( ( ( ""3D CNN"" OR ""VoxNet"" OR ""submanifold sparse CNN"" ) AND ( ""3D data"" OR ""pointcloud"" OR ""point cloud"" ) AND ( ""construction industry"" OR ""building"" OR ""AEC"" OR ""BIM"" ) ) ) AND PUBYEAR > 2007 AND PUBYEAR < 2025 AND ( LIMIT-TO ( DOCTYPE,""ar"" ) OR LIMIT-TO ( DOCTYPE,""cp"" ) )  AND ( LIMIT-TO ( LANGUAGE,""English"" ) ) ",,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,
Pu S.; Xie L.; Ji M.; Zhao Y.; Liu W.; Wang L.; Zhao Y.; Yang F.; Qiu D.,"Pu, S. (57544300600); Xie, L. (57209339128); Ji, M. (57209338346); Zhao, Y. (57211497184); Liu, W. (58360740200); Wang, L. (58455540300); Zhao, Y. (57209348956); Yang, F. (57209339512); Qiu, D. (57209347853)",57544300600; 57209339128; 57209338346; 57211497184; 58360740200; 58455540300; 57209348956; 57209339512; 57209347853,Real-time powerline corridor inspection by edge computing of uav lidar data,2019,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",42,2/W13,,547,551,4,20,10.5194/isprs-archives-XLII-2-W13-547-2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067518427&doi=10.5194%2fisprs-archives-XLII-2-W13-547-2019&partnerID=40&md5=61dac4fd105370085674a97c88985286,"This paper presents an innovative power line corridor inspection approach using UAV LiDAR edge computing and 4G real real-time transmission. First, sample point clouds of power towers are manually classified and decomposed into components according to five mainstream tower types: T type, V type, n type, I type and owl head type. A deep learning AI agent, named ""Tovos Age Agent"" internally, is trained by supervised deep learning the sample data sets under a 3D CNN framework. Second, laser points of power line corridors are simultaneously classified into Ground, Vegetation, Tower, Cable, and Building types using semantic feature constraints during the UAV-borne LiDAR acquisition process, and then tower types are further recognized by Tovos Agent for strain span separation. Spatial and topological relations between Cable points and other types are analyzed according to industry standards to identify potential risks at the same time. Finally, all potential risks are organized as industry standard reports and transmitted onto central server via 4G data link, so that maintenance personal can be notified the risks as soon as possible. Tests on LiDAR data of 1000 KV power line show the promising results of the proposed method. © Authors 2019.",Edge Computing; Powerline Inspection; UAV LiDAR,Conference paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85067518427
Gong Z.; Lin H.; Zhang D.; Luo Z.; Zelek J.; Chen Y.; Nurunnabi A.; Wang C.; Li J.,"Gong, Zheng (57217431593); Lin, Haojia (57211896260); Zhang, Dedong (57190168740); Luo, Zhipeng (57200602927); Zelek, John (6603746225); Chen, Yiping (56233739200); Nurunnabi, Abdul (26638910100); Wang, Cheng (36990982800); Li, Jonathan (57235557700)",57217431593; 57211896260; 57190168740; 57200602927; 6603746225; 56233739200; 26638910100; 36990982800; 57235557700,A Frustum-based probabilistic framework for 3D object detection by fusion of LiDAR and camera data,2020,ISPRS Journal of Photogrammetry and Remote Sensing,159,,,90,100,10,32,10.1016/j.isprsjprs.2019.10.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075265725&doi=10.1016%2fj.isprsjprs.2019.10.015&partnerID=40&md5=e011c6f58f720c2eb13a237110167d21,"This paper presents a real-time 3D object detector based on LiDAR based Simultaneous Localization and Mapping (LiDAR-SLAM). The 3D point clouds acquired by mobile LiDAR systems, within the environment of buildings, are usually highly sparse, irregularly distributed, and often contain occlusion and structural ambiguity. Existing 3D object detection methods based on Convolutional Neural Networks (CNNs) rely heavily on both the stability of the 3D features and a large amount of labelling. A key challenge is efficient detection of 3D objects in point clouds of large-scale building environments without pre-training the 3D CNN model. To project image-based object detection results and LiDAR-SLAM results onto a 3D probability map, we combine visual and range information into a frustum-based probabilistic framework. As such, we solve the sparse and noise problem in LiDAR-SLAM data, in which any point cloud descriptor can hardly be applied. The 3D object detection results, obtained using both backpack LiDAR dataset and the well-known KITTI Vision Benchmark Suite, show that our method outperforms the state-of-the-art methods for object localization and bounding box estimation. © 2019",3D object detection; CNN; Deep learning; LiDAR point clouds; MLS; SLAM,Article,Final,,Scopus,2-s2.0-85075265725
Zhao N.,"Zhao, Na (56432013800)",56432013800,End2End semantic segmentation for 3D indoor scenes,2018,MM 2018 - Proceedings of the 2018 ACM Multimedia Conference,,,,810,814,4,6,10.1145/3240508.3243933,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058240533&doi=10.1145%2f3240508.3243933&partnerID=40&md5=6cb4682b2409a90e36d5486389dc3676,"This research is concerned with semantic segmentation of 3D point clouds arising from videos of 3D indoor scenes. It is an important building block of 3D scene understanding and has promising applications such as augmented reality and robotics. Although various deep learning based approaches have been proposed to replicate the success of 2D semantic segmentation in 3D domain, they either result in severe information loss or fail to model the geometric structures well. In this paper, we aim to model the local and global geometric structures of 3D scenes by designing an end-to-end 3D semantic segmentation framework. It captures the local geometries from point-level feature learning and voxel-level aggregation, models the global structures via 3D CNN, and enforces label consistency with high-order CRF. Through preliminary experiments conducted on two indoor datasets, we describe our insights on the proposed approach, and present some directions to be pursued in the future. © 2018 Association for Computing Machinery.",,Conference paper,Final,,Scopus,2-s2.0-85058240533
